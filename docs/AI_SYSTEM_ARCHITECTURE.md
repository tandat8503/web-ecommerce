# ðŸ¤– GIáº¢I THÃCH Cáº¤U TRÃšC Há»† THá»NG AI

## ðŸ“ Cáº¤U TRÃšC THá»¨ Má»¤C

```
ai/
â”œâ”€â”€ app.py                          # ðŸš€ Main application - Entry point
â”œâ”€â”€ prompts.py                      # ðŸ“ Táº¥t cáº£ prompts cho AI
â”œâ”€â”€ agents.py                       # ðŸ¤– Äá»‹nh nghÄ©a cÃ¡c AI Agents
â”œâ”€â”€ config.py                       # âš™ï¸ Cáº¥u hÃ¬nh há»‡ thá»‘ng
â”œâ”€â”€ requirements.txt                # ðŸ“¦ Dependencies
â”‚
â”œâ”€â”€ core/                           # ðŸ”§ Core utilities
â”‚   â”œâ”€â”€ db.py                       # Database connection pool
â”‚   â”œâ”€â”€ utils.py                    # Helper functions
â”‚   â””â”€â”€ conversation.py             # Conversation history manager
â”‚
â”œâ”€â”€ shared/                         # ðŸ”— Shared modules
â”‚   â””â”€â”€ llm_client.py               # LLM client (Gemini API)
â”‚
â”œâ”€â”€ services/                       # ðŸŽ¯ Business logic services
â”‚   â”œâ”€â”€ chatbot/
â”‚   â”‚   â”œâ”€â”€ improved_user_chatbot.py    # User chatbot vá»›i memory
â”‚   â”‚   â””â”€â”€ user_chatbot.py             # User chatbot cÆ¡ báº£n
â”‚   â””â”€â”€ legal/
â”‚       â”œâ”€â”€ improved_legal_service.py   # Legal chatbot nÃ¢ng cao
â”‚       â””â”€â”€ legal_service.py            # Legal chatbot cÆ¡ báº£n
â”‚
â”œâ”€â”€ mcps/                           # ðŸ› ï¸ MCP Tools (Model Context Protocol)
â”‚   â”œâ”€â”€ helpers.py                  # Tool helper functions
â”‚   â””â”€â”€ tools.py                    # Tool definitions
â”‚
â””â”€â”€ documents/                      # ðŸ“š Legal documents for RAG
    â””â”€â”€ legal/
        â””â”€â”€ *.txt                   # VÄƒn báº£n phÃ¡p luáº­t
```

---

## ðŸ“„ CHI TIáº¾T Tá»ªNG FILE

### 1. `app.py` - Main Application ðŸš€

**Chá»©c nÄƒng**: Entry point cá»§a há»‡ thá»‘ng AI, khá»Ÿi táº¡o Flask server

**Nhiá»‡m vá»¥**:
- Khá»Ÿi táº¡o Flask app
- Äá»‹nh nghÄ©a API endpoints:
  - `POST /chat/user` - User chatbot (tÆ° váº¥n sáº£n pháº©m)
  - `POST /chat/admin` - Admin chatbot (business analytics)
  - `POST /chat/legal` - Legal chatbot (tÆ° váº¥n phÃ¡p luáº­t)
- Xá»­ lÃ½ CORS
- Load environment variables

**Code chÃ­nh**:
```python
from flask import Flask, request, jsonify
from agents import UserChatbotAgent, AdminChatbotAgent
from services.legal.improved_legal_service import improved_legal_service

app = Flask(__name__)

@app.route('/chat/user', methods=['POST'])
async def chat_user():
    # Xá»­ lÃ½ chat vá»›i user
    data = request.json
    user_message = data.get('message')
    
    agent = UserChatbotAgent()
    response = await agent.process_message(user_message)
    return jsonify(response)

@app.route('/chat/admin', methods=['POST'])
async def chat_admin():
    # Xá»­ lÃ½ chat vá»›i admin
    ...

@app.route('/chat/legal', methods=['POST'])
async def chat_legal():
    # Xá»­ lÃ½ tÆ° váº¥n phÃ¡p luáº­t
    ...
```

**Khi nÃ o cháº¡y**: `python app.py` Ä‘á»ƒ start server

---

### 2. `prompts.py` - Prompt Templates ðŸ“

**Chá»©c nÄƒng**: LÆ°u trá»¯ Táº¤T Cáº¢ prompts cho AI

**CÃ¡c prompts chÃ­nh**:

#### User Chatbot Prompts:
```python
USER_CHATBOT_SYSTEM_PROMPT = """
Báº¡n lÃ  ChuyÃªn gia tÆ° váº¥n ná»™i tháº¥t cao cáº¥p...
- ThÃ¢n thiá»‡n, nhiá»‡t tÃ¬nh
- Ghi nhá»› context
- ÄÆ°a ra gá»£i Ã½ phÃ¹ há»£p
"""

USER_CHATBOT_CONSULTANT_PROMPT = """
Dá»¯ liá»‡u sáº£n pháº©m: {products_data}
YÃªu cáº§u: {user_message}

Nhiá»‡m vá»¥:
1. Khá»›p nhu cáº§u
2. PhÃ¢n tÃ­ch
3. TÆ° váº¥n
4. So sÃ¡nh
5. Cross-sell
"""
```

#### Admin Chatbot Prompts:
```python
ADMIN_CHATBOT_SYSTEM_PROMPT = """
You are an Admin Chatbot specialized in business intelligence...
- Revenue analysis
- Customer sentiment
- Report generation
"""
```

#### Legal Chatbot Prompts:
```python
LEGAL_CONSULTANT_SYSTEM_PROMPT = """
Báº¡n lÃ  Trá»£ lÃ½ Luáº­t sÆ° AI...
- TÃ¬m kiáº¿m vÄƒn báº£n phÃ¡p luáº­t
- TrÃ­ch dáº«n chÃ­nh xÃ¡c
- TÃ­nh toÃ¡n thuáº¿
"""
```

**Khi nÃ o sá»­a**: Khi muá»‘n thay Ä‘á»•i cÃ¡ch AI tráº£ lá»i, giá»ng Ä‘iá»‡u, hoáº·c hÆ°á»›ng dáº«n

---

### 3. `agents.py` - AI Agents ðŸ¤–

**Chá»©c nÄƒng**: Äá»‹nh nghÄ©a cÃ¡c AI Agent classes

**CÃ¡c Agent chÃ­nh**:

#### BaseAgent (Abstract class):
```python
class BaseAgent:
    """Base class cho táº¥t cáº£ agents"""
    def __init__(self, agent_type, system_prompt):
        self.agent_type = agent_type
        self.system_prompt = system_prompt
        self.llm_client = LLMClientFactory.create_client()
        self.tool_client = ToolClient()
    
    async def process_message(self, user_message, context):
        # 1. Classify intent
        # 2. Call tools
        # 3. Generate response
        pass
```

#### UserChatbotAgent:
```python
class UserChatbotAgent(BaseAgent):
    """Agent tÆ° váº¥n sáº£n pháº©m cho khÃ¡ch hÃ ng"""
    
    async def _classify_intent(self, user_message):
        # PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh:
        # - greeting
        # - product_search
        # - price_inquiry
        # - product_detail
        # - comparison
        pass
    
    async def _call_tools(self, intent, user_message):
        # Gá»i tools phÃ¹ há»£p:
        # - search_products
        # - get_product_details
        pass
    
    async def _generate_response(self, tool_result, user_message):
        # Táº¡o response tá»« LLM
        pass
```

#### AdminChatbotAgent:
```python
class AdminChatbotAgent(BaseAgent):
    """Agent phÃ¢n tÃ­ch business cho admin"""
    
    async def _call_tools(self, intent, user_message):
        # Gá»i tools:
        # - get_revenue_analytics
        # - summarize_sentiment_by_product
        # - generate_report
        pass
```

**Khi nÃ o sá»­a**: Khi muá»‘n thÃªm agent má»›i hoáº·c thay Ä‘á»•i logic xá»­ lÃ½

---

### 4. `config.py` - Configuration âš™ï¸

**Chá»©c nÄƒng**: Cáº¥u hÃ¬nh há»‡ thá»‘ng

```python
import os
from dotenv import load_dotenv

load_dotenv()

# Database
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 3306)),
    'user': os.getenv('DB_USER', 'root'),
    'password': os.getenv('DB_PASSWORD', ''),
    'database': os.getenv('DB_NAME', 'ecommerce')
}

# LLM
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
GEMINI_MODEL = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash')

# App
DEBUG = os.getenv('DEBUG', 'False') == 'True'
PORT = int(os.getenv('PORT', 5000))
```

**Khi nÃ o sá»­a**: Khi thÃªm config má»›i hoáº·c thay Ä‘á»•i settings

---

### 5. `core/db.py` - Database Connection ðŸ’¾

**Chá»©c nÄƒng**: Quáº£n lÃ½ connection pool Ä‘áº¿n MySQL

```python
import aiomysql
from config import DB_CONFIG

# Connection pool
pool = None

async def init_pool():
    """Khá»Ÿi táº¡o connection pool"""
    global pool
    pool = await aiomysql.create_pool(
        host=DB_CONFIG['host'],
        port=DB_CONFIG['port'],
        user=DB_CONFIG['user'],
        password=DB_CONFIG['password'],
        db=DB_CONFIG['database'],
        minsize=5,
        maxsize=10
    )

async def get_conn():
    """Láº¥y connection tá»« pool"""
    return await pool.acquire()

async def release_conn(conn):
    """Tráº£ connection vá» pool"""
    pool.release(conn)
```

**Khi nÃ o dÃ¹ng**: Khi cáº§n query database trong agents/services

---

### 6. `core/utils.py` - Helper Functions ðŸ”§

**Chá»©c nÄƒng**: CÃ¡c hÃ m tiá»‡n Ã­ch

```python
def extract_price_filter(text):
    """TrÃ­ch xuáº¥t giÃ¡ tá»« text
    
    VD: "dÆ°á»›i 5 triá»‡u" -> (None, 5000000)
        "tá»« 2tr Ä‘áº¿n 5tr" -> (2000000, 5000000)
    """
    import re
    
    # Pattern: "dÆ°á»›i X triá»‡u"
    match = re.search(r'dÆ°á»›i\s+(\d+)\s*(?:triá»‡u|tr)', text)
    if match:
        return (None, int(match.group(1)) * 1000000)
    
    # Pattern: "tá»« X Ä‘áº¿n Y triá»‡u"
    match = re.search(r'tá»«\s+(\d+)\s*(?:tr|triá»‡u).*?Ä‘áº¿n\s+(\d+)\s*(?:tr|triá»‡u)', text)
    if match:
        return (int(match.group(1)) * 1000000, int(match.group(2)) * 1000000)
    
    return (None, None)

def clean_product_query(text):
    """LÃ m sáº¡ch query
    
    VD: "TÃ¬m bÃ n lÃ m viá»‡c" -> "bÃ n lÃ m viá»‡c"
        "Cho tÃ´i xem gháº¿" -> "gháº¿"
    """
    # Remove stopwords
    stopwords = ['tÃ¬m', 'cho tÃ´i', 'xem', 'mua', 'cÃ³', 'khÃ´ng']
    for word in stopwords:
        text = text.replace(word, '')
    return text.strip()
```

**Khi nÃ o dÃ¹ng**: Khi cáº§n xá»­ lÃ½ text, extract thÃ´ng tin

---

### 7. `core/conversation.py` - Conversation Memory ðŸ§ 

**Chá»©c nÄƒng**: LÆ°u trá»¯ lá»‹ch sá»­ há»™i thoáº¡i

```python
class ConversationHistory:
    """Quáº£n lÃ½ lá»‹ch sá»­ há»™i thoáº¡i"""
    
    def __init__(self):
        self.sessions = {}  # {session_id: [messages]}
    
    def add_message(self, session_id, role, content, metadata=None):
        """ThÃªm message vÃ o session"""
        if session_id not in self.sessions:
            self.sessions[session_id] = []
        
        self.sessions[session_id].append({
            'role': role,  # 'user' or 'assistant'
            'content': content,
            'metadata': metadata,
            'timestamp': datetime.now()
        })
    
    def get_history(self, session_id, limit=5):
        """Láº¥y lá»‹ch sá»­ gáº§n nháº¥t"""
        if session_id not in self.sessions:
            return []
        return self.sessions[session_id][-limit:]
    
    def get_context(self, session_id):
        """Láº¥y context (last_products, last_intent)"""
        # TrÃ­ch xuáº¥t thÃ´ng tin tá»« metadata
        pass

# Global instance
conversation_history = ConversationHistory()
```

**Khi nÃ o dÃ¹ng**: Äá»ƒ chatbot nhá»› ngá»¯ cáº£nh há»™i thoáº¡i

---

### 8. `shared/llm_client.py` - LLM Client ðŸ§ 

**Chá»©c nÄƒng**: Giao tiáº¿p vá»›i Gemini API

```python
import google.generativeai as genai
from config import GEMINI_API_KEY, GEMINI_MODEL

class GeminiClient:
    """Client Ä‘á»ƒ gá»i Gemini API"""
    
    def __init__(self):
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel(GEMINI_MODEL)
    
    async def generate_simple(self, prompt, system_instruction, temperature=0.7, max_tokens=2048):
        """Gá»i Gemini API Ä‘Æ¡n giáº£n"""
        try:
            response = self.model.generate_content(
                prompt,
                generation_config={
                    'temperature': temperature,
                    'max_output_tokens': max_tokens
                }
            )
            
            return {
                'success': True,
                'content': response.text,
                'truncated': response.finish_reason == 2
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

class LLMClientFactory:
    """Factory Ä‘á»ƒ táº¡o LLM client"""
    
    @staticmethod
    def create_client():
        return GeminiClient()
```

**Khi nÃ o dÃ¹ng**: Khi cáº§n gá»i AI Ä‘á»ƒ generate text

---

### 9. `services/chatbot/improved_user_chatbot.py` - User Chatbot Service ðŸ’¬

**Chá»©c nÄƒng**: Service xá»­ lÃ½ chat vá»›i user (cÃ³ memory)

**Äáº·c Ä‘iá»ƒm**:
- Intent detection (greeting, product_search, price_inquiry, etc.)
- Conversation memory
- Context-aware responses
- Follow-up questions

```python
class ImprovedUserChatbotService:
    """User chatbot vá»›i conversation memory"""
    
    async def process_message(self, user_message, context):
        # 1. Get conversation history
        session_id = context.get('session_id')
        conv_history = conversation_history.get_history(session_id)
        
        # 2. Detect intent
        intent = await self._detect_intent(user_message, conv_history)
        
        # 3. Execute handler
        if intent == 'greeting':
            response = await self._handle_greeting(...)
        elif intent == 'product_search':
            response = await self._handle_product_search(...)
        elif intent == 'follow_up':
            response = await self._handle_follow_up(...)
        
        # 4. Save to history
        conversation_history.add_message(session_id, 'user', user_message)
        conversation_history.add_message(session_id, 'assistant', response)
        
        return response
```

**Khi nÃ o dÃ¹ng**: ÄÆ°á»£c gá»i tá»« `app.py` endpoint `/chat/user`

---

### 10. `services/legal/improved_legal_service.py` - Legal Chatbot Service âš–ï¸

**Chá»©c nÄƒng**: TÆ° váº¥n phÃ¡p luáº­t vá»›i RAG (Retrieval-Augmented Generation)

**Flow**:
1. User há»i vá» luáº­t
2. Search trong documents/legal/ Ä‘á»ƒ tÃ¬m vÄƒn báº£n liÃªn quan
3. TrÃ­ch xuáº¥t context tá»« vÄƒn báº£n
4. Gá»­i context + question cho LLM
5. LLM tráº£ lá»i dá»±a trÃªn context

```python
class ImprovedLegalService:
    """Legal chatbot vá»›i RAG"""
    
    async def process_query(self, user_query):
        # 1. Search legal documents
        relevant_docs = await self._search_documents(user_query)
        
        # 2. Extract context
        context = self._extract_context(relevant_docs)
        
        # 3. Generate response with LLM
        prompt = LEGAL_CONSULTANT_RAG_PROMPT.format(
            context=context,
            user_query=user_query
        )
        
        response = await self.llm_client.generate_simple(
            prompt=prompt,
            system_instruction=LEGAL_CONSULTANT_SYSTEM_PROMPT
        )
        
        return response
```

**Khi nÃ o dÃ¹ng**: ÄÆ°á»£c gá»i tá»« `app.py` endpoint `/chat/legal`

---

### 11. `mcps/tools.py` - MCP Tools ðŸ› ï¸

**Chá»©c nÄƒng**: Äá»‹nh nghÄ©a cÃ¡c tools mÃ  AI cÃ³ thá»ƒ gá»i

**Tools chÃ­nh**:

```python
# Product tools
async def search_products(query, limit=5, min_price=None, max_price=None):
    """TÃ¬m kiáº¿m sáº£n pháº©m"""
    conn = await get_conn()
    try:
        sql = "SELECT * FROM products WHERE name LIKE %s"
        params = [f"%{query}%"]
        
        if min_price:
            sql += " AND price >= %s"
            params.append(min_price)
        
        if max_price:
            sql += " AND price <= %s"
            params.append(max_price)
        
        async with conn.cursor() as cur:
            await cur.execute(sql, params)
            rows = await cur.fetchall()
            return {'success': True, 'products': rows}
    finally:
        await release_conn(conn)

async def get_product_details(product_name_or_id):
    """Láº¥y chi tiáº¿t sáº£n pháº©m"""
    # Query database Ä‘á»ƒ láº¥y thÃ´ng tin Ä‘áº§y Ä‘á»§
    pass

# Analytics tools
async def get_revenue_analytics(period):
    """PhÃ¢n tÃ­ch doanh thu"""
    # Query orders, tÃ­nh tá»•ng revenue
    pass

async def summarize_sentiment_by_product(product_id):
    """Tá»•ng há»£p sentiment theo sáº£n pháº©m"""
    # Query reviews, phÃ¢n tÃ­ch sentiment
    pass
```

**Khi nÃ o dÃ¹ng**: Agents gá»i tools thÃ´ng qua `ToolClient`

---

### 12. `mcps/helpers.py` - Tool Helpers ðŸ”§

**Chá»©c nÄƒng**: Helper functions cho tools

```python
async def search_products_helper(query, limit, min_price, max_price):
    """Wrapper cho search_products tool"""
    result = await search_products(query, limit, min_price, max_price)
    return json.dumps(result, ensure_ascii=False)

async def get_product_details_helper(product_name_or_id):
    """Wrapper cho get_product_details tool"""
    result = await get_product_details(product_name_or_id)
    return json.dumps(result, ensure_ascii=False)
```

**Khi nÃ o dÃ¹ng**: ÄÆ°á»£c gá»i tá»« agents

---

## ðŸ”„ FLOW HOÃ€N CHá»ˆNH

### User Chat Flow:

```
1. Frontend gá»­i POST /chat/user
   Body: {message: "TÃ¬m bÃ n dÆ°á»›i 5 triá»‡u", session_id: "abc123"}
   
2. app.py nháº­n request
   â†“
3. Khá»Ÿi táº¡o UserChatbotAgent
   â†“
4. Agent.process_message()
   â”œâ”€ Get conversation history (session_id)
   â”œâ”€ Classify intent â†’ "product_search"
   â”œâ”€ Extract params â†’ {query: "bÃ n", max_price: 5000000}
   â”œâ”€ Call tool: search_products(query="bÃ n", max_price=5000000)
   â”œâ”€ Tool query database â†’ return products
   â”œâ”€ Generate response vá»›i LLM
   â”‚  â”œâ”€ Prompt: USER_CHATBOT_CONSULTANT_PROMPT
   â”‚  â”œâ”€ Context: products data
   â”‚  â””â”€ LLM generate: "Dáº¡ bÃªn em cÃ³ máº¥y máº«u bÃ n nÃ y..."
   â””â”€ Save to conversation history
   
5. Return response to frontend
   {
     success: true,
     response: {
       text: "Dáº¡ bÃªn em cÃ³...",
       type: "product_recommendation",
       data: [product cards]
     }
   }
```

### Admin Chat Flow:

```
1. Frontend gá»­i POST /chat/admin
   Body: {message: "Doanh thu thÃ¡ng 12", user_id: 1}
   
2. app.py nháº­n request
   â†“
3. Khá»Ÿi táº¡o AdminChatbotAgent
   â†“
4. Agent.process_message()
   â”œâ”€ Classify intent â†’ "revenue_analysis"
   â”œâ”€ Call tool: get_revenue_analytics(period="2024-12")
   â”œâ”€ Tool query orders â†’ calculate revenue
   â”œâ”€ Generate response vá»›i LLM
   â””â”€ Return insights + recommendations
   
5. Return response to frontend
```

---

## ðŸŽ¯ KHI NÃ€O Sá»¬A FILE NÃ€O?

| Má»¥c Ä‘Ã­ch | File cáº§n sá»­a |
|----------|--------------|
| Thay Ä‘á»•i cÃ¡ch AI tráº£ lá»i | `prompts.py` |
| ThÃªm greeting message | `services/chatbot/improved_user_chatbot.py` (dÃ²ng 280) |
| ThÃªm intent má»›i | `agents.py` â†’ `_classify_intent()` |
| ThÃªm tool má»›i | `mcps/tools.py` |
| Thay Ä‘á»•i database query | `mcps/tools.py` hoáº·c `core/db.py` |
| ThÃªm endpoint má»›i | `app.py` |
| Thay Ä‘á»•i config | `config.py` hoáº·c `.env` |
| ThÃªm helper function | `core/utils.py` |
| Thay Ä‘á»•i LLM model | `config.py` â†’ `GEMINI_MODEL` |

---

## ðŸ“Š DEPENDENCIES

```
Flask==3.0.0              # Web framework
aiomysql==0.2.0           # Async MySQL driver
google-generativeai==0.3.0 # Gemini API
python-dotenv==1.0.0      # Environment variables
```

---

**Created**: 2025-12-29
**Version**: 1.0
**Status**: âœ… DOCUMENTATION COMPLETE
