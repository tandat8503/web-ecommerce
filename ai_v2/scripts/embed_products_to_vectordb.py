#!/usr/bin/env python3
"""
Embed products into VectorDB for semantic search
"""
import asyncio
import json
import sys
from pathlib import Path
from sentence_transformers import SentenceTransformer
import chromadb

sys.path.insert(0, str(Path(__file__).parent.parent))


def create_rich_text_for_product(product: dict) -> str:
    """Create rich text for embedding"""
    
    # Basic info
    text = f"{product['name']} - {product['brand']}\n\n"
    text += f"Danh má»¥c: {product['category']}\n"
    text += f"GiÃ¡: {product['final_price']:,.0f}Ä‘"
    
    if product.get('sale_price'):
        text += f" (Giáº£m giÃ¡ tá»« {product['price']:,.0f}Ä‘)"
    
    text += "\n\n"
    
    # Description
    if product.get('description'):
        text += f"MÃ´ táº£:\n{product['description']}\n\n"
    
    # Specs from first variant
    if product.get('variants') and len(product['variants']) > 0:
        variant = product['variants'][0]
        text += "ThÃ´ng sá»‘ ká»¹ thuáº­t:\n"
        
        dims = variant.get('dimensions', {})
        if dims.get('width') and dims.get('depth') and dims.get('height'):
            text += f"- KÃ­ch thÆ°á»›c: {dims['width']}x{dims['depth']}x{dims['height']}cm"
            
            # Infer suitable space
            width = dims['width']
            if width < 120:
                text += " (Nhá» gá»n, phÃ¹ há»£p vÄƒn phÃ²ng nhá»)\n"
            elif width < 160:
                text += " (Vá»«a pháº£i, phÃ¹ há»£p vÄƒn phÃ²ng trung bÃ¬nh)\n"
            else:
                text += " (Rá»™ng rÃ£i, phÃ¹ há»£p vÄƒn phÃ²ng lá»›n)\n"
        
        if variant.get('material'):
            text += f"- Cháº¥t liá»‡u: {variant['material']}\n"
        
        if variant.get('color'):
            text += f"- MÃ u sáº¯c: {variant['color']}\n"
        
        if variant.get('weight_capacity'):
            text += f"- Táº£i trá»ng: {variant['weight_capacity']}kg\n"
        
        if variant.get('warranty'):
            text += f"- Báº£o hÃ nh: {variant['warranty']}\n"
    
    # Infer use cases based on category and price
    text += "\nPhÃ¹ há»£p:\n"
    
    category = product['category'].lower()
    price = product['final_price']
    
    if 'bÃ n' in category:
        if price < 3000000:
            text += "- Há»c sinh, sinh viÃªn\n- LÃ m viá»‡c táº¡i nhÃ  (WFH)\n- VÄƒn phÃ²ng nhá»\n"
        elif price < 7000000:
            text += "- NhÃ¢n viÃªn vÄƒn phÃ²ng\n- Freelancer\n- VÄƒn phÃ²ng vá»«a vÃ  nhá»\n"
        else:
            text += "- GiÃ¡m Ä‘á»‘c, quáº£n lÃ½\n- VÄƒn phÃ²ng cao cáº¥p\n- PhÃ²ng lÃ m viá»‡c riÃªng\n"
    
    elif 'gháº¿' in category:
        if 'gaming' in category:
            text += "- Game thá»§\n- Streamer\n- LÃ m viá»‡c nhiá»u giá»\n"
        elif 'cÃ´ng thÃ¡i há»c' in category or 'ergonomic' in category:
            text += "- Láº­p trÃ¬nh viÃªn\n- NhÃ¢n viÃªn vÄƒn phÃ²ng\n- Ngá»“i 8+ giá»/ngÃ y\n"
        elif price < 2000000:
            text += "- Há»c sinh, sinh viÃªn\n- VÄƒn phÃ²ng tiáº¿t kiá»‡m\n"
        else:
            text += "- NhÃ¢n viÃªn vÄƒn phÃ²ng\n- PhÃ²ng há»p\n- Sá»­ dá»¥ng lÃ¢u dÃ i\n"
    
    # Rating if available
    if product.get('rating') and product['rating'] > 0:
        text += f"\nÄÃ¡nh giÃ¡: {product['rating']}/5"
        if product.get('review_count'):
            text += f" ({product['review_count']} Ä‘Ã¡nh giÃ¡)"
    
    return text.strip()


def embed_products():
    """Embed products into VectorDB"""
    print("="*80)
    print("ğŸ”„ EMBEDDING PRODUCTS TO VECTORDB")
    print("="*80)
    
    # 1. Load products
    json_file = Path(__file__).parent / "products_for_embedding.json"
    
    if not json_file.exists():
        print(f"\nâŒ Error: {json_file} not found!")
        print("Run: python scripts/export_products_for_embedding.py first")
        return
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    products = data['products']
    print(f"\nğŸ“Š Loaded {len(products)} products")
    
    # 2. Initialize ChromaDB
    print(f"\nğŸ”§ Initializing ChromaDB...")
    
    chroma_path = Path(__file__).parent.parent / "chroma_db"
    chroma_path.mkdir(exist_ok=True)
    
    client = chromadb.PersistentClient(path=str(chroma_path))
    
    # Delete old collection if exists
    try:
        client.delete_collection("product_catalog")
        print(f"  âœ… Deleted old product_catalog collection")
    except:
        pass
    
    collection = client.create_collection(
        name="product_catalog",
        metadata={"description": "Product catalog for semantic search"}
    )
    
    print(f"  âœ… Created new product_catalog collection")
    
    # 3. Load embedding model
    print(f"\nğŸ¤– Loading embedding model...")
    model = SentenceTransformer("intfloat/multilingual-e5-small")
    print(f"  âœ… Model loaded")
    
    # 4. Create embeddings
    print(f"\nğŸ“ Creating rich text and embeddings...")
    
    documents = []
    metadatas = []
    ids = []
    
    for i, product in enumerate(products):
        # Create rich text
        rich_text = create_rich_text_for_product(product)
        
        documents.append(rich_text)
        metadatas.append({
            "product_id": product['id'],
            "name": product['name'],
            "category": product['category'],
            "brand": product['brand'],
            "price": float(product['final_price']),
            "slug": product['slug']
        })
        ids.append(f"product_{product['id']}")
        
        if (i + 1) % 20 == 0:
            print(f"  âœ… Processed {i + 1}/{len(products)} products...")
    
    print(f"  âœ… Created {len(documents)} rich texts")
    
    # 5. Generate embeddings
    print(f"\nğŸ”¢ Generating embeddings...")
    embeddings = model.encode(documents, show_progress_bar=True)
    print(f"  âœ… Generated {len(embeddings)} embeddings")
    
    # 6. Add to ChromaDB
    print(f"\nğŸ’¾ Adding to ChromaDB...")
    
    # Add in batches
    batch_size = 100
    for i in range(0, len(documents), batch_size):
        end_idx = min(i + batch_size, len(documents))
        
        collection.add(
            embeddings=embeddings[i:end_idx].tolist(),
            documents=documents[i:end_idx],
            metadatas=metadatas[i:end_idx],
            ids=ids[i:end_idx]
        )
        
        print(f"  âœ… Added batch {i//batch_size + 1}/{(len(documents)-1)//batch_size + 1}")
    
    # 7. Verify
    print(f"\nğŸ” Verifying...")
    count = collection.count()
    print(f"  âœ… Total documents in collection: {count}")
    
    # Test search
    test_query = "bÃ n lÃ m viá»‡c cho vÄƒn phÃ²ng nhá»"
    test_embedding = model.encode([test_query])
    
    results = collection.query(
        query_embeddings=test_embedding.tolist(),
        n_results=3
    )
    
    print(f"\nğŸ§ª Test search: '{test_query}'")
    print(f"  Top 3 results:")
    for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
        print(f"\n  {i+1}. {metadata['name']}")
        print(f"     Category: {metadata['category']}")
        print(f"     Price: {metadata['price']:,.0f}Ä‘")
        print(f"     Distance: {results['distances'][0][i]:.4f}")
    
    print(f"\n" + "="*80)
    print(f"âœ… EMBEDDING COMPLETE!")
    print(f"="*80)
    print(f"\nğŸ“Š Summary:")
    print(f"  - Total products embedded: {count}")
    print(f"  - Collection: product_catalog")
    print(f"  - Location: {chroma_path}/product_catalog")
    print(f"\nğŸ¯ Next: Create ProductVectorService")


def main():
    embed_products()


if __name__ == "__main__":
    main()
