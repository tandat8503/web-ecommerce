"""
Script test ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng Vector DB cho vƒÉn b·∫£n lu·∫≠t
Ki·ªÉm tra xem c√≥ c·∫ßn embed v√† chunk l·∫°i kh√¥ng
"""
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict
import json

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.legal.vector_service import LegalVectorService

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VectorDBTester:
    """Class ƒë·ªÉ test v√† ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng Vector DB"""
    
    def __init__(self):
        self.vector_service = LegalVectorService()
        self.test_queries = [
            "Ng∆∞·ªùi ƒë·∫°i di·ªán theo ph√°p lu·∫≠t c·ªßa doanh nghi·ªáp",
            "Th·ªß t·ª•c ƒëƒÉng k√Ω th√†nh l·∫≠p c√¥ng ty",
            "V·ªën ƒëi·ªÅu l·ªá t·ªëi thi·ªÉu",
            "Nghƒ©a v·ª• n·ªôp thu·∫ø",
            "Quy·ªÅn v√† nghƒ©a v·ª• c·ªßa c·ªï ƒë√¥ng",
            "Gi·∫£i th·ªÉ doanh nghi·ªáp",
            "Chuy·ªÉn ƒë·ªïi lo·∫°i h√¨nh doanh nghi·ªáp",
            "Quy ƒë·ªãnh v·ªÅ lao ƒë·ªông",
            "H·ª£p ƒë·ªìng lao ƒë·ªông",
            "ƒêi·ªÅu ki·ªán kinh doanh"
        ]
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ t·ªïng quan v·ªÅ collection"""
        stats = self.vector_service.get_collection_stats()
        total_chunks = stats["total_chunks"]
        
        if total_chunks == 0:
            logger.warning("‚ö†Ô∏è Collection r·ªóng! Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c embed.")
            return stats
        
        # Get sample ƒë·ªÉ ph√¢n t√≠ch metadata
        try:
            sample_results = self.vector_service._collection.get(limit=min(100, total_chunks))
            
            # Ph√¢n t√≠ch metadata
            doc_types = defaultdict(int)
            statuses = defaultdict(int)
            doc_names = defaultdict(int)
            metadata_completeness = {
                "has_doc_name": 0,
                "has_doc_type": 0,
                "has_article": 0,
                "has_chapter": 0,
                "has_source_id": 0,
                "has_keywords": 0,
                "has_effective_date": 0
            }
            
            if sample_results["ids"]:
                for metadata in sample_results["metadatas"]:
                    if metadata.get("doc_type"):
                        doc_types[metadata["doc_type"]] += 1
                    if metadata.get("status"):
                        statuses[metadata["status"]] += 1
                    if metadata.get("doc_name"):
                        doc_names[metadata["doc_name"]] += 1
                    
                    # Ki·ªÉm tra ƒë·ªô ƒë·∫ßy ƒë·ªß metadata
                    if metadata.get("doc_name"):
                        metadata_completeness["has_doc_name"] += 1
                    if metadata.get("doc_type"):
                        metadata_completeness["has_doc_type"] += 1
                    if metadata.get("article"):
                        metadata_completeness["has_article"] += 1
                    if metadata.get("chapter"):
                        metadata_completeness["has_chapter"] += 1
                    if metadata.get("source_id"):
                        metadata_completeness["has_source_id"] += 1
                    if metadata.get("keywords"):
                        metadata_completeness["has_keywords"] += 1
                    if metadata.get("effective_date"):
                        metadata_completeness["has_effective_date"] += 1
                
                sample_size = len(sample_results["metadatas"])
                for key in metadata_completeness:
                    metadata_completeness[key] = {
                        "count": metadata_completeness[key],
                        "percentage": round(metadata_completeness[key] / sample_size * 100, 2) if sample_size > 0 else 0
                    }
            
            stats.update({
                "doc_types": dict(doc_types),
                "statuses": dict(statuses),
                "unique_doc_names": len(doc_names),
                "sample_doc_names": list(doc_names.keys())[:10],
                "metadata_completeness": metadata_completeness,
                "sample_size": len(sample_results["metadatas"]) if sample_results["metadatas"] else 0
            })
        except Exception as e:
            logger.error(f"L·ªói khi ph√¢n t√≠ch metadata: {e}")
        
        return stats
    
    def test_search_quality(self, top_k: int = 5) -> Dict[str, Any]:
        """Test ch·∫•t l∆∞·ª£ng search v·ªõi c√°c query m·∫´u"""
        results = {
            "total_queries": len(self.test_queries),
            "successful_searches": 0,
            "failed_searches": 0,
            "avg_results_per_query": 0,
            "avg_distance_score": 0.0,
            "query_results": [],
            "recommendations": []
        }
        
        total_results = 0
        total_distance = 0.0
        distance_count = 0
        low_quality_searches = []
        
        for query in self.test_queries:
            try:
                search_results = self.vector_service.search(
                    query=query,
                    top_k=top_k,
                    status="active"
                )
                
                if search_results:
                    results["successful_searches"] += 1
                    total_results += len(search_results)
                    
                    # T√≠nh distance trung b√¨nh (c√†ng th·∫•p c√†ng t·ªët)
                    query_distances = []
                    for result in search_results:
                        if result.get("distance") is not None:
                            query_distances.append(result["distance"])
                            total_distance += result["distance"]
                            distance_count += 1
                    
                    avg_distance = sum(query_distances) / len(query_distances) if query_distances else None
                    
                    # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng (distance < 0.3 l√† t·ªët, > 0.5 l√† k√©m)
                    quality = "T·ªët"
                    if avg_distance:
                        if avg_distance > 0.5:
                            quality = "K√©m"
                            low_quality_searches.append({
                                "query": query,
                                "avg_distance": avg_distance,
                                "results_count": len(search_results)
                            })
                        elif avg_distance > 0.3:
                            quality = "Trung b√¨nh"
                    
                    results["query_results"].append({
                        "query": query,
                        "results_count": len(search_results),
                        "avg_distance": round(avg_distance, 4) if avg_distance else None,
                        "quality": quality,
                        "top_result": {
                            "id": search_results[0]["id"],
                            "article": search_results[0]["metadata"].get("article", ""),
                            "doc_name": search_results[0]["metadata"].get("doc_name", ""),
                            "distance": search_results[0].get("distance")
                        } if search_results else None
                    })
                else:
                    results["failed_searches"] += 1
                    results["query_results"].append({
                        "query": query,
                        "results_count": 0,
                        "avg_distance": None,
                        "quality": "Kh√¥ng c√≥ k·∫øt qu·∫£",
                        "top_result": None
                    })
                    
            except Exception as e:
                logger.error(f"L·ªói khi search query '{query}': {e}")
                results["failed_searches"] += 1
        
        # T√≠nh trung b√¨nh
        if results["successful_searches"] > 0:
            results["avg_results_per_query"] = round(total_results / results["successful_searches"], 2)
        
        if distance_count > 0:
            results["avg_distance_score"] = round(total_distance / distance_count, 4)
        
        # ƒê∆∞a ra recommendations
        if results["failed_searches"] > len(self.test_queries) * 0.3:
            results["recommendations"].append(
                "‚ö†Ô∏è C√≥ > 30% queries kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£. C·∫ßn ki·ªÉm tra l·∫°i vi·ªác embed ho·∫∑c th√™m d·ªØ li·ªáu."
            )
        
        if results["avg_distance_score"] > 0.5:
            results["recommendations"].append(
                f"‚ö†Ô∏è Distance score trung b√¨nh cao ({results['avg_distance_score']:.4f}). "
                "Ch·∫•t l∆∞·ª£ng embedding c√≥ th·ªÉ kh√¥ng t·ªët. C√¢n nh·∫Øc re-embed v·ªõi model t·ªët h∆°n."
            )
        
        if len(low_quality_searches) > len(self.test_queries) * 0.4:
            results["recommendations"].append(
                f"‚ö†Ô∏è C√≥ {len(low_quality_searches)}/{len(self.test_queries)} queries c√≥ ch·∫•t l∆∞·ª£ng k√©m. "
                "C·∫ßn review l·∫°i c√°ch chunk v√† embed."
            )
        
        return results
    
    def test_chunk_quality(self, sample_size: int = 50) -> Dict[str, Any]:
        """Ki·ªÉm tra ch·∫•t l∆∞·ª£ng chunks (k√≠ch th∆∞·ªõc, metadata, etc.)"""
        try:
            sample_results = self.vector_service._collection.get(limit=sample_size)
            
            if not sample_results["ids"] or len(sample_results["ids"]) == 0:
                return {
                    "error": "Kh√¥ng c√≥ d·ªØ li·ªáu trong collection"
                }
            
            chunk_lengths = []
            chunks_without_text = 0
            chunks_with_missing_metadata = 0
            required_metadata_fields = ["doc_name", "doc_type", "article"]
            
            for i, doc in enumerate(sample_results["documents"]):
                # Ki·ªÉm tra ƒë·ªô d√†i text
                if doc:
                    chunk_lengths.append(len(doc))
                else:
                    chunks_without_text += 1
                
                # Ki·ªÉm tra metadata
                metadata = sample_results["metadatas"][i]
                missing_fields = [field for field in required_metadata_fields if not metadata.get(field)]
                if missing_fields:
                    chunks_with_missing_metadata += 1
            
            avg_length = sum(chunk_lengths) / len(chunk_lengths) if chunk_lengths else 0
            max_length = max(chunk_lengths) if chunk_lengths else 0
            min_length = min(chunk_lengths) if chunk_lengths else 0
            
            # Ph√¢n t√≠ch ƒë·ªô d√†i
            # Chunks qu√° ng·∫Øn (< 50 chars) ho·∫∑c qu√° d√†i (> 3000 chars) c√≥ th·ªÉ c√≥ v·∫•n ƒë·ªÅ
            too_short = sum(1 for length in chunk_lengths if length < 50)
            too_long = sum(1 for length in chunk_lengths if length > 3000)
            
            recommendations = []
            
            if too_short > len(chunk_lengths) * 0.1:
                recommendations.append(
                    f"‚ö†Ô∏è C√≥ {too_short} chunks qu√° ng·∫Øn (< 50 k√Ω t·ª±). "
                    "C√≥ th·ªÉ c·∫ßn merge c√°c chunks nh·ªè l·∫°i."
                )
            
            if too_long > len(chunk_lengths) * 0.1:
                recommendations.append(
                    f"‚ö†Ô∏è C√≥ {too_long} chunks qu√° d√†i (> 3000 k√Ω t·ª±). "
                    "C√≥ th·ªÉ c·∫ßn chunk nh·ªè h∆°n ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c search."
                )
            
            if chunks_without_text > 0:
                recommendations.append(
                    f"‚ö†Ô∏è C√≥ {chunks_without_text} chunks kh√¥ng c√≥ text. C·∫ßn ki·ªÉm tra l·∫°i qu√° tr√¨nh embed."
                )
            
            return {
                "sample_size": len(sample_results["ids"]),
                "avg_chunk_length": round(avg_length, 2),
                "max_chunk_length": max_length,
                "min_chunk_length": min_length,
                "too_short_chunks": too_short,
                "too_long_chunks": too_long,
                "chunks_without_text": chunks_without_text,
                "chunks_with_missing_metadata": chunks_with_missing_metadata,
                "recommendations": recommendations
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi ki·ªÉm tra chunk quality: {e}")
            return {
                "error": str(e)
            }
    
    def test_metadata_consistency(self) -> Dict[str, Any]:
        """Ki·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa metadata"""
        try:
            # L·∫•y t·∫•t c·∫£ documents (c√≥ th·ªÉ t·ªën th·ªùi gian n·∫øu DB l·ªõn)
            all_results = self.vector_service._collection.get()
            
            if not all_results["ids"] or len(all_results["ids"]) == 0:
                return {
                    "error": "Kh√¥ng c√≥ d·ªØ li·ªáu trong collection"
                }
            
            # Nh√≥m theo doc_name v√† ki·ªÉm tra
            docs_by_name = defaultdict(list)
            for i, metadata in enumerate(all_results["metadatas"]):
                doc_name = metadata.get("doc_name", "Unknown")
                docs_by_name[doc_name].append({
                    "id": all_results["ids"][i],
                    "metadata": metadata
                })
            
            # Ki·ªÉm tra consistency
            inconsistent_docs = []
            for doc_name, chunks in docs_by_name.items():
                # Ki·ªÉm tra xem t·∫•t c·∫£ chunks c√≥ c√πng doc_type kh√¥ng
                doc_types = set(chunk["metadata"].get("doc_type") for chunk in chunks)
                source_ids = set(chunk["metadata"].get("source_id") for chunk in chunks if chunk["metadata"].get("source_id"))
                
                if len(doc_types) > 1:
                    inconsistent_docs.append({
                        "doc_name": doc_name,
                        "issue": f"C√≥ {len(doc_types)} lo·∫°i doc_type kh√°c nhau: {list(doc_types)}",
                        "chunks_count": len(chunks)
                    })
                
                if len(source_ids) > 1:
                    inconsistent_docs.append({
                        "doc_name": doc_name,
                        "issue": f"C√≥ {len(source_ids)} source_id kh√°c nhau: {list(source_ids)}",
                        "chunks_count": len(chunks)
                    })
            
            recommendations = []
            if inconsistent_docs:
                recommendations.append(
                    f"‚ö†Ô∏è T√¨m th·∫•y {len(inconsistent_docs)} vƒÉn b·∫£n c√≥ metadata kh√¥ng nh·∫•t qu√°n. "
                    "C·∫ßn review v√† fix."
                )
            
            return {
                "total_documents": len(docs_by_name),
                "total_chunks": len(all_results["ids"]),
                "inconsistent_documents": inconsistent_docs[:10],  # Ch·ªâ hi·ªÉn th·ªã 10 ƒë·∫ßu ti√™n
                "recommendations": recommendations
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi ki·ªÉm tra metadata consistency: {e}")
            return {
                "error": str(e)
            }
    
    def generate_report(self) -> Dict[str, Any]:
        """T·∫°o b√°o c√°o t·ªïng h·ª£p"""
        logger.info("=" * 80)
        logger.info("B·∫ÆT ƒê·∫¶U TEST VECTOR DB CHO VƒÇN B·∫¢N LU·∫¨T")
        logger.info("=" * 80)
        
        report = {
            "collection_stats": {},
            "search_quality": {},
            "chunk_quality": {},
            "metadata_consistency": {},
            "overall_recommendations": []
        }
        
        # 1. Ki·ªÉm tra th·ªëng k√™ collection
        logger.info("\n[1/4] Ki·ªÉm tra th·ªëng k√™ collection...")
        report["collection_stats"] = self.get_collection_stats()
        logger.info(f"‚úì T·ªïng s·ªë chunks: {report['collection_stats'].get('total_chunks', 0)}")
        
        if report["collection_stats"].get("total_chunks", 0) == 0:
            report["overall_recommendations"].append(
                "üö® KH·∫®N C·∫§P: Collection r·ªóng! C·∫ßn ch·∫°y script process_legal_documents.py ƒë·ªÉ embed d·ªØ li·ªáu."
            )
            return report
        
        # 2. Test ch·∫•t l∆∞·ª£ng search
        logger.info("\n[2/4] Test ch·∫•t l∆∞·ª£ng search...")
        report["search_quality"] = self.test_search_quality()
        logger.info(f"‚úì Successful searches: {report['search_quality']['successful_searches']}/{report['search_quality']['total_queries']}")
        logger.info(f"‚úì Avg distance score: {report['search_quality']['avg_distance_score']}")
        
        # 3. Ki·ªÉm tra ch·∫•t l∆∞·ª£ng chunks
        logger.info("\n[3/4] Ki·ªÉm tra ch·∫•t l∆∞·ª£ng chunks...")
        report["chunk_quality"] = self.test_chunk_quality()
        if "error" not in report["chunk_quality"]:
            logger.info(f"‚úì Avg chunk length: {report['chunk_quality'].get('avg_chunk_length', 0)} chars")
        
        # 4. Ki·ªÉm tra metadata consistency
        logger.info("\n[4/4] Ki·ªÉm tra t√≠nh nh·∫•t qu√°n metadata...")
        report["metadata_consistency"] = self.test_metadata_consistency()
        if "error" not in report["metadata_consistency"]:
            logger.info(f"‚úì Total documents: {report['metadata_consistency'].get('total_documents', 0)}")
        
        # T·ªïng h·ª£p recommendations
        all_recommendations = []
        
        if report.get("collection_stats", {}).get("metadata_completeness"):
            completeness = report["collection_stats"]["metadata_completeness"]
            low_completeness = [k for k, v in completeness.items() 
                              if isinstance(v, dict) and v.get("percentage", 100) < 70]
            if low_completeness:
                all_recommendations.append(
                    f"‚ö†Ô∏è Metadata thi·∫øu th√¥ng tin: {', '.join(low_completeness)}. "
                    "C·∫ßn c·∫£i thi·ªán qu√° tr√¨nh extract metadata."
                )
        
        all_recommendations.extend(report["search_quality"].get("recommendations", []))
        all_recommendations.extend(report["chunk_quality"].get("recommendations", []))
        all_recommendations.extend(report["metadata_consistency"].get("recommendations", []))
        
        # ƒê∆∞a ra k·∫øt lu·∫≠n cu·ªëi c√πng
        if not all_recommendations:
            all_recommendations.append("‚úÖ Vector DB c√≥ ch·∫•t l∆∞·ª£ng t·ªët! Kh√¥ng c·∫ßn re-embed ho·∫∑c re-chunk.")
        else:
            # Ki·ªÉm tra xem c√≥ c·∫ßn re-embed kh√¥ng
            needs_reembed = False
            needs_rechunk = False
            
            if report["search_quality"].get("avg_distance_score", 0) > 0.5:
                needs_reembed = True
                all_recommendations.append("üî¥ KHUY·∫æN NGH·ªä: C·∫ßn RE-EMBED v·ªõi model t·ªët h∆°n ho·∫∑c t·ªëi ∆∞u h√≥a embedding process.")
            
            chunk_issues = report["chunk_quality"].get("too_short_chunks", 0) + report["chunk_quality"].get("too_long_chunks", 0)
            if chunk_issues > report["chunk_quality"].get("sample_size", 0) * 0.2:
                needs_rechunk = True
                all_recommendations.append("üî¥ KHUY·∫æN NGH·ªä: C·∫ßn RE-CHUNK ƒë·ªÉ c·∫£i thi·ªán k√≠ch th∆∞·ªõc chunks.")
            
            if needs_reembed or needs_rechunk:
                all_recommendations.append(
                    f"\nüìã ACTION ITEMS:\n"
                    f"  - Re-embed: {'C√ì' if needs_reembed else 'KH√îNG'}\n"
                    f"  - Re-chunk: {'C√ì' if needs_rechunk else 'KH√îNG'}\n"
                    f"  - Command: cd ai && python scripts/process_legal_documents.py"
                )
        
        report["overall_recommendations"] = all_recommendations
        
        return report
    
    def print_report(self, report: Dict[str, Any]):
        """In b√°o c√°o ra console v·ªõi format ƒë·∫πp"""
        print("\n" + "=" * 80)
        print("B√ÅO C√ÅO ƒê√ÅNH GI√Å VECTOR DB CHO VƒÇN B·∫¢N LU·∫¨T")
        print("=" * 80)
        
        # Collection Stats
        print("\nüìä TH·ªêNG K√ä COLLECTION:")
        stats = report.get("collection_stats", {})
        print(f"  ‚Ä¢ T·ªïng s·ªë chunks: {stats.get('total_chunks', 0)}")
        if stats.get("unique_doc_names"):
            print(f"  ‚Ä¢ S·ªë vƒÉn b·∫£n: {stats.get('unique_doc_names', 0)}")
        if stats.get("doc_types"):
            print(f"  ‚Ä¢ Lo·∫°i vƒÉn b·∫£n: {', '.join(stats['doc_types'].keys())}")
        
        if stats.get("metadata_completeness"):
            print("\n  üìã ƒê·ªô ƒë·∫ßy ƒë·ªß Metadata:")
            for field, info in stats["metadata_completeness"].items():
                if isinstance(info, dict):
                    print(f"    - {field}: {info['percentage']}% ({info['count']}/{stats.get('sample_size', 0)})")
        
        # Search Quality
        print("\nüîç CH·∫§T L∆Ø·ª¢NG SEARCH:")
        search_quality = report.get("search_quality", {})
        print(f"  ‚Ä¢ Queries th√†nh c√¥ng: {search_quality.get('successful_searches', 0)}/{search_quality.get('total_queries', 0)}")
        print(f"  ‚Ä¢ Avg distance score: {search_quality.get('avg_distance_score', 0):.4f} "
              f"(< 0.3: T·ªët, 0.3-0.5: TB, > 0.5: K√©m)")
        
        if search_quality.get("query_results"):
            print("\n  üìù K·∫øt qu·∫£ test queries:")
            for qr in search_quality["query_results"][:5]:  # Ch·ªâ hi·ªÉn th·ªã 5 ƒë·∫ßu ti√™n
                print(f"    ‚Ä¢ '{qr['query'][:50]}...': {qr['results_count']} k·∫øt qu·∫£, "
                      f"distance: {qr.get('avg_distance', 'N/A')}, {qr.get('quality', 'N/A')}")
        
        # Chunk Quality
        print("\nüì¶ CH·∫§T L∆Ø·ª¢NG CHUNKS:")
        chunk_quality = report.get("chunk_quality", {})
        if "error" not in chunk_quality:
            print(f"  ‚Ä¢ Avg length: {chunk_quality.get('avg_chunk_length', 0):.0f} k√Ω t·ª±")
            print(f"  ‚Ä¢ Min/Max: {chunk_quality.get('min_chunk_length', 0)}/{chunk_quality.get('max_chunk_length', 0)} k√Ω t·ª±")
            print(f"  ‚Ä¢ Qu√° ng·∫Øn (< 50): {chunk_quality.get('too_short_chunks', 0)} chunks")
            print(f"  ‚Ä¢ Qu√° d√†i (> 3000): {chunk_quality.get('too_long_chunks', 0)} chunks")
        
        # Recommendations
        print("\nüí° KHUY·∫æN NGH·ªä:")
        recommendations = report.get("overall_recommendations", [])
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                print(f"  {i}. {rec}")
        else:
            print("  ‚úÖ Kh√¥ng c√≥ v·∫•n ƒë·ªÅ g√¨!")
        
        print("\n" + "=" * 80)
    
    def save_report_json(self, report: Dict[str, Any], output_file: str = "vector_db_test_report.json"):
        """L∆∞u b√°o c√°o d∆∞·ªõi d·∫°ng JSON"""
        output_path = Path(__file__).parent / output_file
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        logger.info(f"‚úì ƒê√£ l∆∞u b√°o c√°o v√†o: {output_path}")


def main():
    """Main function"""
    tester = VectorDBTester()
    
    # T·∫°o b√°o c√°o
    report = tester.generate_report()
    
    # In ra console
    tester.print_report(report)
    
    # L∆∞u file JSON
    tester.save_report_json(report)
    
    logger.info("\n‚úÖ Ho√†n th√†nh test!")


if __name__ == "__main__":
    main()




