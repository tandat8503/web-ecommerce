# ğŸš€ PHÆ¯Æ NG ÃN IMPLEMENT: NÃ‚NG Cáº¤P USER CHATBOT

## ğŸ“‹ Tá»•ng Quan

### **Má»¥c tiÃªu:**
NÃ¢ng cáº¥p User Chatbot tá»« "show sáº£n pháº©m" â†’ "chuyÃªn gia tÆ° váº¥n"

### **CÃ´ng nghá»‡:**
- VectorDB: ChromaDB (Ä‘Ã£ cÃ³)
- Embedding: multilingual-e5-small (Ä‘Ã£ cÃ³)
- LLM: Gemini 1.5 Flash (Ä‘Ã£ cÃ³)

### **Thá»i gian:** 2-3 giá»

---

## ğŸ¯ PHASE 1: EMBED PRODUCTS VÃ€O VECTORDB (1 giá»)

### **BÆ°á»›c 1.1: Export Products tá»« MySQL**

**File:** `scripts/export_products_for_embedding.py`

**Chá»©c nÄƒng:**
```python
# Káº¿t ná»‘i MySQL
# Query: SELECT * FROM products WHERE is_active = 1
# Láº¥y thÃªm: categories, brands, specs
# Export ra JSON
```

**Output:** `scripts/products_data.json`

**Data structure:**
```json
{
  "products": [
    {
      "id": 123,
      "name": "BÃ n lÃ m viá»‡c F42",
      "slug": "ban-lam-viec-f42",
      "category": "BÃ n lÃ m viá»‡c",
      "brand": "Ná»™i Tháº¥t VP",
      "price": 5000000,
      "sale_price": null,
      "description": "BÃ n lÃ m viá»‡c compact...",
      "specs": {
        "dimensions": "120x60x75",
        "material": "MDF Melamine",
        "colors": ["NÃ¢u gá»—", "Tráº¯ng"],
        "weight": "25kg"
      },
      "images": ["url1", "url2"],
      "stock": 50,
      "rating": 4.5,
      "reviews_count": 120
    }
  ]
}
```

---

### **BÆ°á»›c 1.2: Táº¡o Rich Text for Embedding**

**File:** `services/chatbot/product_embedder.py`

**Chá»©c nÄƒng:**
```python
def create_product_embedding_text(product: dict) -> str:
    """
    Táº¡o text phong phÃº cho embedding
    Bao gá»“m: specs, use cases, pros/cons
    """
    
    # Template
    text = f"""
    {product['name']} - {product['brand']}
    
    ThÃ´ng sá»‘ ká»¹ thuáº­t:
    - KÃ­ch thÆ°á»›c: {specs['dimensions']} (DxRxC)
    - Cháº¥t liá»‡u: {specs['material']}
    - MÃ u sáº¯c: {', '.join(specs['colors'])}
    - Trá»ng lÆ°á»£ng: {specs['weight']}
    
    MÃ´ táº£:
    {product['description']}
    
    PhÃ¹ há»£p:
    {infer_suitable_for(product)}  # AI generate
    
    Æ¯u Ä‘iá»ƒm:
    {infer_pros(product)}  # AI generate
    
    NhÆ°á»£c Ä‘iá»ƒm:
    {infer_cons(product)}  # AI generate
    
    GiÃ¡: {product['price']:,}Ä‘
    Danh má»¥c: {product['category']}
    ÄÃ¡nh giÃ¡: {product['rating']}/5 ({product['reviews_count']} reviews)
    """
    
    return text
```

**AI-enhanced fields:**
- `suitable_for`: DÃ¹ng LLM Ä‘á»ƒ infer tá»« specs
- `pros`: DÃ¹ng LLM Ä‘á»ƒ analyze
- `cons`: DÃ¹ng LLM Ä‘á»ƒ analyze

**Example:**
```
Input: BÃ n F42, 120x60cm, 5tr
Output: 
  PhÃ¹ há»£p: VÄƒn phÃ²ng nhá» 8-12mÂ², WFH, sinh viÃªn
  Æ¯u Ä‘iá»ƒm: Nhá» gá»n, tiáº¿t kiá»‡m khÃ´ng gian, giÃ¡ tá»‘t
  NhÆ°á»£c Ä‘iá»ƒm: KhÃ´ng phÃ¹ há»£p vÄƒn phÃ²ng lá»›n
```

---

### **BÆ°á»›c 1.3: Embed vÃ o VectorDB**

**File:** `scripts/embed_products_to_vectordb.py`

**Workflow:**
```python
1. Load products_data.json
2. For each product:
   - Create rich embedding text
   - Generate embedding (multilingual-e5-small)
   - Create chunk with metadata
3. Upsert to ChromaDB collection: "product_catalog"
4. Verify: Check total chunks
```

**Chunk structure:**
```python
{
    "id": "product_123",
    "text_for_embedding": "...",  # Rich text
    "metadata": {
        "product_id": 123,
        "name": "BÃ n F42",
        "category": "BÃ n lÃ m viá»‡c",
        "price": 5000000,
        "price_range": "mid",  # low/mid/high
        "dimensions": "120x60x75",
        "suitable_for": ["vÄƒn phÃ²ng nhá»", "WFH"],
        "slug": "ban-lam-viec-f42"
    }
}
```

**Command:**
```bash
python scripts/embed_products_to_vectordb.py
```

**Output:**
```
âœ… Embedded 500 products
Collection: product_catalog
Total chunks: 500
```

---

## ğŸ¯ PHASE 2: Táº O PRODUCT VECTOR SERVICE (30 phÃºt)

### **BÆ°á»›c 2.1: Create ProductVectorService**

**File:** `services/chatbot/product_vector_service.py`

**Chá»©c nÄƒng:**
```python
class ProductVectorService:
    def __init__(self):
        self.collection = chroma_client.get_collection("product_catalog")
        self.embedding_model = SentenceTransformer("intfloat/multilingual-e5-small")
    
    def search_products(
        self, 
        query: str, 
        top_k: int = 5,
        filters: dict = None
    ) -> List[dict]:
        """
        Vector search for products
        
        Args:
            query: User query (semantic)
            top_k: Number of results
            filters: Price range, category, etc.
        
        Returns:
            List of products with full metadata
        """
        # 1. Embed query
        query_embedding = self.embedding_model.encode(query)
        
        # 2. Search
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=filters  # {"price": {"$lt": 10000000}}
        )
        
        # 3. Format results
        products = []
        for i, metadata in enumerate(results['metadatas'][0]):
            products.append({
                "product_id": metadata['product_id'],
                "name": metadata['name'],
                "price": metadata['price'],
                "category": metadata['category'],
                "slug": metadata['slug'],
                "distance": results['distances'][0][i],
                "full_text": results['documents'][0][i]
            })
        
        return products
```

---

## ğŸ¯ PHASE 3: UPDATE CHATBOT LOGIC (30 phÃºt)

### **BÆ°á»›c 3.1: Add Hybrid Search**

**File:** `services/chatbot/improved_user_chatbot.py`

**Update `_handle_product_search()`:**

```python
async def _handle_product_search(self, user_message, intent_data):
    """
    Hybrid search: MySQL (fast) + VectorDB (smart)
    """
    
    # 1. Classify query complexity
    is_complex = self._is_complex_query(user_message)
    
    if is_complex:
        # Use VectorDB for semantic search
        products = await self._vector_search_products(user_message, intent_data)
    else:
        # Use MySQL for simple keyword search
        products = await self._mysql_search_products(user_message, intent_data)
    
    # 2. Generate expert advice
    response = await self._generate_expert_advice(
        query=user_message,
        products=products,
        search_method="vector" if is_complex else "mysql"
    )
    
    return response

def _is_complex_query(self, query: str) -> bool:
    """
    Determine if query needs semantic search
    
    Complex queries:
    - Mentions specs (kÃ­ch thÆ°á»›c, cháº¥t liá»‡u)
    - Mentions use case (vÄƒn phÃ²ng nhá», designer)
    - Comparison (so sÃ¡nh, khÃ¡c nhau)
    - Advice (nÃªn chá»n, phÃ¹ há»£p)
    
    Simple queries:
    - Product name (BÃ n F42)
    - Category (bÃ n lÃ m viá»‡c)
    - Brand (Ná»™i Tháº¥t VP)
    """
    complex_keywords = [
        "phÃ¹ há»£p", "nÃªn chá»n", "so sÃ¡nh", "khÃ¡c nhau",
        "kÃ­ch thÆ°á»›c", "cháº¥t liá»‡u", "nhá»", "lá»›n",
        "vÄƒn phÃ²ng nhá»", "designer", "giÃ¡m Ä‘á»‘c",
        "tiáº¿t kiá»‡m", "cao cáº¥p", "sang trá»ng"
    ]
    
    return any(kw in query.lower() for kw in complex_keywords)

async def _vector_search_products(self, query, intent_data):
    """Search using VectorDB"""
    from services.chatbot.product_vector_service import ProductVectorService
    
    vector_service = ProductVectorService()
    
    # Build filters
    filters = {}
    if intent_data.get('min_price'):
        filters['price'] = {'$gte': intent_data['min_price']}
    if intent_data.get('max_price'):
        if 'price' in filters:
            filters['price']['$lte'] = intent_data['max_price']
        else:
            filters['price'] = {'$lte': intent_data['max_price']}
    
    # Search
    results = vector_service.search_products(
        query=query,
        top_k=5,
        filters=filters if filters else None
    )
    
    # Get full product details from MySQL
    product_ids = [r['product_id'] for r in results]
    products = await self._get_products_by_ids(product_ids)
    
    # Attach vector search metadata
    for product in products:
        for result in results:
            if result['product_id'] == product['id']:
                product['vector_distance'] = result['distance']
                product['vector_text'] = result['full_text']
    
    return products
```

---

## ğŸ¯ PHASE 4: IMPROVE LLM PROMPTS (30 phÃºt)

### **BÆ°á»›c 4.1: Create Expert Advice Generator**

**File:** `services/chatbot/improved_user_chatbot.py`

**New method:**

```python
async def _generate_expert_advice(
    self, 
    query: str, 
    products: List[dict],
    search_method: str = "mysql"
) -> dict:
    """
    Generate expert advice using LLM
    
    Args:
        query: User query
        products: List of products (with full specs)
        search_method: "mysql" or "vector"
    
    Returns:
        Response with expert advice
    """
    
    # 1. Prepare product context
    products_context = []
    for p in products:
        # Get vector text if available (has full specs, pros/cons)
        if search_method == "vector" and p.get('vector_text'):
            product_info = p['vector_text']
        else:
            # Build from MySQL data
            product_info = self._build_product_info(p)
        
        products_context.append({
            "name": p['name'],
            "price": p['price'],
            "sale_price": p.get('sale_price'),
            "category": p['category'],
            "full_info": product_info
        })
    
    # 2. Build expert prompt
    prompt = f"""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n ná»™i tháº¥t vÄƒn phÃ²ng vá»›i 10 nÄƒm kinh nghiá»‡m.

KhÃ¡ch hÃ ng há»i: "{query}"

Sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c:
{json.dumps(products_context, ensure_ascii=False, indent=2)}

HÃ£y tÆ° váº¥n CHI TIáº¾T nhÆ° má»™t chuyÃªn gia:

**1. PhÃ¢n tÃ­ch nhu cáº§u:**
- Hiá»ƒu khÃ¡ch cáº§n gÃ¬ (khÃ´ng gian, ngÃ¢n sÃ¡ch, má»¥c Ä‘Ã­ch)
- ÄÆ°a ra nháº­n xÃ©t ngáº¯n gá»n

**2. Gá»£i Ã½ sáº£n pháº©m:** (cho tá»«ng sáº£n pháº©m, tá»‘i Ä‘a 2-3 sáº£n pháº©m)

ğŸŒŸ **[TÃªn sáº£n pháº©m]** ([GiÃ¡])
   âœ… [ThÃ´ng sá»‘ quan trá»ng 1] - [Lá»£i Ã­ch]
   âœ… [ThÃ´ng sá»‘ quan trá»ng 2] - [Lá»£i Ã­ch]
   âœ… [ThÃ´ng sá»‘ quan trá»ng 3] - [Lá»£i Ã­ch]
   ğŸ’° GiÃ¡: [Nháº­n xÃ©t vá» giÃ¡]
   
   ğŸ‘‰ PhÃ¹ há»£p náº¿u: [Ai nÃªn chá»n]

**3. So sÃ¡nh:** (náº¿u cÃ³ nhiá»u sáº£n pháº©m)
- Äiá»ƒm khÃ¡c biá»‡t chÃ­nh
- Sáº£n pháº©m nÃ o phÃ¹ há»£p vá»›i tá»«ng nhu cáº§u

**4. Gá»£i Ã½ cuá»‘i:**
ğŸ¯ **Gá»£i Ã½ cá»§a em:** [KhuyÃªn nÃªn chá»n sáº£n pháº©m nÃ o vÃ  Táº I SAO]

Anh/chá»‹ muá»‘n em tÆ° váº¥n thÃªm vá» [aspect] khÃ´ng áº¡? ğŸ˜Š

**LÆ°u Ã½:**
- DÃ¹ng Markdown (bold **, bullet points, emoji)
- ThÃ¢n thiá»‡n, xÆ°ng "em" - "anh/chá»‹"
- ChuyÃªn nghiá»‡p nhÆ°ng khÃ´ng khÃ´ khan
- Chá»‘t Ä‘Æ¡n tá»± nhiÃªn, khÃ´ng Ã©p buá»™c
- KHÃ”NG liá»‡t kÃª láº¡i toÃ n bá»™ sáº£n pháº©m (Frontend Ä‘Ã£ show cards)
- Chá»‰ phÃ¢n tÃ­ch 2-3 sáº£n pháº©m CHÃNH
"""
    
    # 3. Generate response
    ai_response = await self.llm_client.generate_simple(
        prompt=prompt,
        system_instruction="Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n ná»™i tháº¥t nhiá»‡t tÃ¬nh, chuyÃªn nghiá»‡p.",
        temperature=0.7,
        max_tokens=1000
    )
    
    answer_text = ai_response.get("content", "Dáº¡ Ä‘Ã¢y lÃ  gá»£i Ã½ cá»§a em áº¡.")
    
    # 4. Format response
    return {
        "success": True,
        "response": {
            "text": answer_text,
            "type": "expert_advice",
            "data": self._format_product_cards(products[:3])  # Max 3 cards
        },
        "agent_type": "user_chatbot_improved",
        "search_method": search_method
    }
```

---

## ğŸ¯ PHASE 5: TESTING & VERIFICATION (30 phÃºt)

### **BÆ°á»›c 5.1: Create Test Script**

**File:** `scripts/test_product_chatbot.py`

**Test cases:**
```python
test_cases = [
    # Simple queries (MySQL)
    {
        "query": "BÃ n F42",
        "expected_method": "mysql",
        "expected_products": ["BÃ n F42"]
    },
    
    # Complex queries (VectorDB)
    {
        "query": "BÃ n cho vÄƒn phÃ²ng nhá», diá»‡n tÃ­ch 10mÂ²",
        "expected_method": "vector",
        "expected_features": ["kÃ­ch thÆ°á»›c nhá»", "tiáº¿t kiá»‡m khÃ´ng gian"]
    },
    
    # Comparison
    {
        "query": "So sÃ¡nh bÃ n F42 vÃ  G100",
        "expected_method": "vector",
        "expected_products": ["BÃ n F42", "BÃ n G100"],
        "expected_features": ["so sÃ¡nh", "khÃ¡c biá»‡t"]
    },
    
    # Advice
    {
        "query": "BÃ n nÃ o phÃ¹ há»£p cho designer?",
        "expected_method": "vector",
        "expected_features": ["rá»™ng", "nhiá»u ngÄƒn", "ergonomic"]
    }
]
```

**Run test:**
```bash
python scripts/test_product_chatbot.py
```

**Expected output:**
```
Test 1: BÃ n F42
  âœ… Method: mysql (expected: mysql)
  âœ… Found: BÃ n F42
  âœ… Response quality: Good

Test 2: BÃ n cho vÄƒn phÃ²ng nhá»
  âœ… Method: vector (expected: vector)
  âœ… Features mentioned: kÃ­ch thÆ°á»›c nhá», tiáº¿t kiá»‡m khÃ´ng gian
  âœ… Response quality: Excellent

...

Overall: 4/4 tests passed (100%)
```

---

## ğŸ“Š SUMMARY: NHá»®NG GÃŒ Sáº¼ ÄÆ¯á»¢C LÃ€M

### **1. Scripts Má»›i:**
```
scripts/
â”œâ”€â”€ export_products_for_embedding.py    # Export MySQL â†’ JSON
â”œâ”€â”€ embed_products_to_vectordb.py       # Embed JSON â†’ VectorDB
â””â”€â”€ test_product_chatbot.py             # Test chatbot quality
```

### **2. Services Má»›i:**
```
services/chatbot/
â”œâ”€â”€ product_embedder.py                 # Create rich embedding text
â””â”€â”€ product_vector_service.py           # Vector search for products
```

### **3. Services Updated:**
```
services/chatbot/
â””â”€â”€ improved_user_chatbot.py            # Add hybrid search + expert advice
```

### **4. VectorDB:**
```
chroma_db/
â””â”€â”€ product_catalog/                    # New collection (500 chunks)
```

---

## ğŸ¯ Káº¾T QUáº¢ MONG Äá»¢I

### **Before:**
```
User: "BÃ n cho vÄƒn phÃ²ng nhá»"
Bot: "Dáº¡ bÃªn em cÃ³ máº¥y máº«u nÃ y: ğŸ˜Š"
     [5 random product cards]
```

### **After:**
```
User: "BÃ n cho vÄƒn phÃ²ng nhá», diá»‡n tÃ­ch 10mÂ²"

Bot: "Dáº¡ em hiá»ƒu rá»“i áº¡! Vá»›i vÄƒn phÃ²ng nhá» 10mÂ², em gá»£i Ã½ 2 máº«u nÃ y:

ğŸŒŸ **BÃ n F42 - Compact Series** (5,000,000Ä‘)
   âœ… KÃ­ch thÆ°á»›c 120x60cm - Vá»ªA Váº¶N cho khÃ´ng gian nhá»
   âœ… Gá»— MDF Melamine - Bá»€N, Dá»„ Vá»† SINH
   âœ… CÃ³ 2 ngÄƒn kÃ©o - TIáº¾T KIá»†M KHÃ”NG GIAN
   ğŸ’° GiÃ¡: PhÃ¹ há»£p ngÃ¢n sÃ¡ch táº§m trung
   
   ğŸ‘‰ PhÃ¹ há»£p náº¿u: Anh/chá»‹ Æ°u tiÃªn TIáº¾T KIá»†M KHÃ”NG GIAN

ğŸ“¦ **BÃ n G100 - Executive** (7,000,000Ä‘)
   âœ… KÃ­ch thÆ°á»›c 140x70cm - Rá»™ng hÆ¡n má»™t chÃºt
   âœ… Gá»— cÃ´ng nghiá»‡p cao cáº¥p - SANG TRá»ŒNG
   âœ… Tá»§ phá»¥ Ä‘i kÃ¨m - NHIá»€U NGÄ‚N chá»©a
   ğŸ’° GiÃ¡: Cao hÆ¡n 40% nhÆ°ng cháº¥t lÆ°á»£ng tá»‘t
   
   ğŸ‘‰ PhÃ¹ há»£p náº¿u: Anh/chá»‹ muá»‘n Bá»€N Äáº¸P, Ä‘áº§u tÆ° lÃ¢u dÃ i

ğŸ¯ **Gá»£i Ã½ cá»§a em:**
Vá»›i vÄƒn phÃ²ng 10mÂ², em khuyÃªn anh/chá»‹ chá»n **BÃ n F42** vÃ¬:
- KÃ­ch thÆ°á»›c 120x60cm Ä‘á»ƒ láº¡i khÃ´ng gian Ä‘i láº¡i thoáº£i mÃ¡i
- GiÃ¡ cáº£ pháº£i chÄƒng hÆ¡n
- Váº«n Ä‘á»§ chá»©c nÄƒng cho cÃ´ng viá»‡c hÃ ng ngÃ y

Anh/chá»‹ muá»‘n em tÆ° váº¥n thÃªm vá» mÃ u sáº¯c hoáº·c phá»¥ kiá»‡n khÃ´ng áº¡? ğŸ˜Š"

[Card: BÃ n F42] [Card: BÃ n G100]
```

---

## â±ï¸ TIMELINE

| Phase | Task | Time |
|-------|------|------|
| 1 | Export + Embed products | 1h |
| 2 | Create ProductVectorService | 30min |
| 3 | Update chatbot logic | 30min |
| 4 | Improve LLM prompts | 30min |
| 5 | Testing & verification | 30min |
| **Total** | | **3h** |

---

## ğŸ’° COST

- Embedding: ~$0.10 (one-time)
- Per query: ~$0.001 (LLM generation)
- Storage: Free (local ChromaDB)

**Total:** ~$0.10 one-time + $0.001/query

---

## âœ… CHECKLIST

- [ ] Phase 1: Export & Embed products
- [ ] Phase 2: Create ProductVectorService
- [ ] Phase 3: Update chatbot logic
- [ ] Phase 4: Improve LLM prompts
- [ ] Phase 5: Test & verify
- [ ] Deploy to production

---

**Báº¡n muá»‘n tÃ´i báº¯t Ä‘áº§u implement khÃ´ng?** ğŸš€

TÃ´i sáº½ lÃ m tá»«ng phase má»™t vÃ  bÃ¡o cÃ¡o tiáº¿n Ä‘á»™ cho báº¡n!
