#!/usr/bin/env python3
"""
Train Model from Database - Train model t·ª´ d·ªØ li·ªáu ƒë√£ t√≠ch h·ª£p trong database
"""

import os
import sys
import sqlite3
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
from pathlib import Path

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from scripts.train_advanced_sentiment import (
    normalize_vietnamese_text, 
    expand_vietnamese_slang, 
    expand_underscore_words,
    extract_sentiment_features,
    LABEL_MAP,
    ID2LABEL
)

DB_PATH = "data/sentiment_training.db"
MODEL_DIR = "models/sentiment/advanced"
MODEL_PATH = f"{MODEL_DIR}/vietnamese_sentiment_model.joblib"

def load_training_data_from_db(db_path: str = DB_PATH) -> pd.DataFrame:
    """Load d·ªØ li·ªáu training t·ª´ SQLite database"""
    print(f"üìÅ Loading data from database: {db_path}")
    
    try:
        conn = sqlite3.connect(db_path)
        
        # Load t·∫•t c·∫£ d·ªØ li·ªáu training t·ª´ database
        query = """
        SELECT text, original_text, label, source_file, confidence, preprocessing_info, created_at
        FROM sentiment_training_data
        ORDER BY created_at DESC
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        print(f"‚úÖ Loaded {len(df)} rows from database")
        
        # Map sentiment label sang text
        def map_label_to_sentiment(label):
            if label == 0: return "negative"
            elif label == 1: return "neutral"
            elif label == 2: return "positive"
            else: return "neutral"
        
        df['sentiment'] = df['label'].apply(map_label_to_sentiment)
        df['source'] = df['source_file']
        
        return df
        
    except Exception as e:
        print(f"‚ùå Error loading from database: {e}")
        return pd.DataFrame()

def preprocess_text(text: str) -> str:
    """Preprocess text v·ªõi x·ª≠ l√Ω ti·∫øng Vi·ªát n√¢ng cao"""
    if not text or pd.isna(text):
        return ""
    
    # Chu·∫©n h√≥a vƒÉn b·∫£n
    text = normalize_vietnamese_text(text)
    
    # M·ªü r·ªông t·ª´ vi·∫øt t·∫Øt
    text = expand_vietnamese_slang(text)
    
    # X·ª≠ l√Ω t·ª´ gh√©p c√≥ d·∫•u g·∫°ch d∆∞·ªõi
    text = expand_underscore_words(text)
    
    return text

def build_advanced_model():
    """X√¢y d·ª±ng model v·ªõi TF-IDF v√† Logistic Regression"""
    print("üîß Building advanced model...")
    
    # TF-IDF Vectorizer v·ªõi parameters t·ªëi ∆∞u cho ti·∫øng Vi·ªát
    vectorizer = TfidfVectorizer(
        max_features=10000,
        ngram_range=(1, 3),  # Unigram, bigram, trigram
        min_df=2,  # T·ª´ ph·∫£i xu·∫•t hi·ªán √≠t nh·∫•t 2 l·∫ßn
        max_df=0.95,  # T·ª´ kh√¥ng ƒë∆∞·ª£c xu·∫•t hi·ªán qu√° 95% documents
        stop_words=None,  # Kh√¥ng d√πng stop words v√¨ c√≥ th·ªÉ m·∫•t th√¥ng tin quan tr·ªçng
        lowercase=True,
        strip_accents='unicode',
        analyzer='word'
    )
    
    # Logistic Regression v·ªõi parameters t·ªëi ∆∞u
    classifier = LogisticRegression(
        random_state=42,
        max_iter=1000,
        C=1.0,  # Regularization strength
        multi_class='ovr'  # One-vs-Rest for multi-class
    )
    
    # Pipeline
    model = Pipeline([
        ('vectorizer', vectorizer),
        ('classifier', classifier)
    ])
    
    return model

def train_and_evaluate(model, X_train, X_val, y_train, y_val):
    """Train v√† evaluate model"""
    print("üîÑ Training model...")
    
    # Train model
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_val)
    y_pred_proba = model.predict_proba(X_val)
    
    # Metrics
    accuracy = accuracy_score(y_val, y_pred)
    print(f"üìä Accuracy: {accuracy:.4f}")
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    print(f"üìä Cross-validation scores: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    
    # Classification report
    print("\nüìä Classification Report:")
    print(classification_report(y_val, y_pred, target_names=['negative', 'neutral', 'positive']))
    
    # Confusion matrix
    print("\nüìä Confusion Matrix:")
    cm = confusion_matrix(y_val, y_pred)
    print(cm)
    
    return model, accuracy, cv_scores

def test_model_predictions(model, test_cases):
    """Test model v·ªõi c√°c test cases"""
    print("\nüîÆ Testing model predictions...")
    
    for text in test_cases:
        # Preprocess text
        processed_text = preprocess_text(text)
        
        # Predict
        prediction = model.predict([processed_text])[0]
        probability = model.predict_proba([processed_text])[0]
        
        # Get confidence
        confidence = max(probability)
        
        print(f"üìù '{text[:50]}{'...' if len(text) > 50 else ''}' ‚Üí {ID2LABEL[prediction]} ({confidence:.3f})")

def save_model_performance(accuracy, cv_scores, model, db_path: str = DB_PATH):
    """L∆∞u performance metrics v√†o database"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # L∆∞u performance metrics
        cursor.execute("""
            INSERT INTO model_performance 
            (model_name, accuracy, f1_score, precision, recall, training_samples, validation_samples, 
             cross_val_scores, confusion_matrix, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            "advanced-vietnamese-sentiment",
            accuracy,
            accuracy,  # F1 score (simplified)
            accuracy,  # Precision (simplified)
            accuracy,  # Recall (simplified)
            0,  # Will be updated
            0,  # Will be updated
            str(cv_scores.tolist()),
            "",  # Confusion matrix
            pd.Timestamp.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
        
        print("‚úÖ Model performance saved to database")
        
    except Exception as e:
        print(f"‚ùå Error saving model performance: {e}")

def main():
    """Main function"""
    print("üöÄ Training Model from Database")
    print("=" * 60)
    
    # 1. Load data from database
    df = load_training_data_from_db()
    
    if len(df) == 0:
        print("‚ùå No data found in database!")
        return
    
    # 2. Preprocess data
    print("üîÑ Preprocessing data...")
    df['processed_text'] = df['text'].apply(preprocess_text)
    
    # Filter out empty texts
    df = df[df['processed_text'].str.len() > 0]
    
    print(f"üìä Final dataset: {len(df)} rows")
    print(f"üìä Sentiment distribution:")
    sentiment_counts = df['sentiment'].value_counts()
    print(sentiment_counts)
    
    # 3. Prepare features and labels
    X = df['processed_text'].values
    y = df['label'].values  # Use numeric labels
    
    # 4. Split data
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"üìä Training samples: {len(X_train)}")
    print(f"üìä Validation samples: {len(X_val)}")
    
    # 5. Build and train model
    model = build_advanced_model()
    trained_model, accuracy, cv_scores = train_and_evaluate(model, X_train, X_val, y_train, y_val)
    
    # 6. Save model
    os.makedirs(MODEL_DIR, exist_ok=True)
    joblib.dump(trained_model, MODEL_PATH)
    print(f"üíæ Model saved to: {MODEL_PATH}")
    
    # 7. Save performance
    save_model_performance(accuracy, cv_scores, trained_model)
    
    # 8. Test predictions
    test_cases = [
        "S·∫£n ph·∫©m r·∫•t t·ªët, ch·∫•t l∆∞·ª£ng cao, giao h√†ng nhanh",
        "T√¥i kh√¥ng h√†i l√≤ng v·ªõi d·ªãch v·ª• n√†y, t·ªá qu√°",
        "S·∫£n ph·∫©m b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
        "Shop ph·ª•c v·ª• t·ªët, shipper th√¢n thi·ªán",
        "H√†ng v·ªÅ b·ªã h·ªèng, r·∫•t th·∫•t v·ªçng",
        "Qu√° tuy·ªát v·ªùi! S·∫Ω mua l·∫°i",
        "Kh√¥ng nh∆∞ mong ƒë·ª£i, ch·∫•t l∆∞·ª£ng k√©m",
        "B√¨nh th∆∞·ªùng th√¥i, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
        "Tuy·ªát v·ªùi! R·∫•t h√†i l√≤ng v·ªõi s·∫£n ph·∫©m",
        "Sp ok, t·∫°m dc",
        "Nma sp rat tot, giao hang nhanh",
        "K dc, sp te qua",
        "Oki, sp dep nma hoi dat",
        "Sp rat hay, se mua lai",
        "K nhu mong doi, chat luong kem",
        "Sp binh thuong, k co gi dac biet",
        "Shop phuc vu tot, shipper than thien",
        "Hang ve bi hong, rat that vong",
        "Qua tuyet voi! Se mua lai",
        "Sp rat tot, chat luong cao, giao hang nhanh",
        "T k hai long vs dich vu nay, te qua",
        "Sp binh thuong, k co gi dac biet",
        "Shop phuc vu tot, shipper than thien",
        "Hang ve bi hong, rat that vong",
        "Sp ok, tam dc",
        "Qua tuyet voi! Se mua lai",
        "K nhu mong doi, chat luong kem",
        "Binh thuong thoi, k co gi noi bat",
        "Tuyet voi! Rat hai long vs sp",
        "S·∫£n_ph·∫©m r·∫•t t·ªët, ch·∫•t_l∆∞·ª£ng cao",
        "D·ªãch_v·ª• giao_h√†ng nhanh ch√≥ng",
        "Kh√°ch_h√†ng h√†i_l√≤ng v·ªõi s·∫£n_ph·∫©m",
        "C·ª≠a_h√†ng ph·ª•c_v·ª• t·ªët, shipper th√¢n_thi·ªán",
        "H√†ng v·ªÅ b·ªã h·ªèng, r·∫•t th·∫•t_v·ªçng",
        "S·∫£n_ph·∫©m b√¨nh_th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c_bi·ªát",
        "Ch·∫•t_l∆∞·ª£ng s·∫£n_ph·∫©m k√©m, gi√°_c·∫£ ƒë·∫Øt",
        "Th·ªùi_gian giao_h√†ng ch·∫≠m, d·ªãch_v·ª• t·ªá",
        "S·∫£n_ph·∫©m ƒë·∫πp, m√†u_s·∫Øc ƒë√∫ng v·ªõi m√¥_t·∫£",
        "K√≠ch_th∆∞·ªõc s·∫£n_ph·∫©m ph√π_h·ª£p, gi√°_th√†nh h·ª£p_l√Ω"
    ]
    
    test_model_predictions(trained_model, test_cases)
    
    print(f"\nüéâ Training completed successfully!")
    print(f"üìä Final accuracy: {accuracy:.4f}")
    print(f"üíæ Model saved to: {MODEL_PATH}")
    print(f"üíæ Database: {DB_PATH}")

if __name__ == "__main__":
    main()
