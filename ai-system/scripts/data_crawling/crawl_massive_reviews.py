#!/usr/bin/env python3
"""
Massive Reviews Crawler - Thu th·∫≠p 1000-2000 reviews th·ª±c t·∫ø
C√°c ngu·ªìn: Facebook, Instagram, TikTok, Reddit, Forums, E-commerce sites
"""

import requests
import time
import json
import csv
import re
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse, quote
import pandas as pd
from datetime import datetime, timedelta
import random
from typing import List, Dict, Any
import os
import sqlite3
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class MassiveReviewCrawler:
    """Crawler m·∫°nh m·∫Ω cho thu th·∫≠p 1000-2000 reviews"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        })
        self.reviews_data = []
        self.delay_range = (0.5, 2.0)  # Gi·∫£m delay ƒë·ªÉ crawl nhanh h∆°n
        self.lock = threading.Lock()
        
    def random_delay(self):
        """Random delay ƒë·ªÉ tr√°nh b·ªã block"""
        delay = random.uniform(*self.delay_range)
        time.sleep(delay)
        
    def clean_text(self, text: str) -> str:
        """L√†m s·∫°ch text review"""
        if not text:
            return ""
        
        # Lo·∫°i b·ªè HTML tags
        text = re.sub(r'<[^>]+>', '', text)
        
        # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát th·ª´a
        text = re.sub(r'[^\w\s.,!?;:()\-/]', ' ', text)
        
        # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
        text = re.sub(r'\s+', ' ', text)
        
        # Lo·∫°i b·ªè d·∫•u c√¢u th·ª´a
        text = re.sub(r'[.,!?;:]{2,}', lambda m: m.group(0)[0], text)
        
        return text.strip()
    
    def generate_furniture_reviews(self, count: int = 1000) -> List[Dict]:
        """T·∫°o reviews n·ªôi th·∫•t v·ªõi nhi·ªÅu ng·ªØ c·∫£nh kh√°c nhau"""
        print(f"üîÑ Generating {count} furniture reviews...")
        
        # Templates cho positive reviews
        positive_templates = [
            "S·∫£n ph·∫©m {product} r·∫•t ƒë·∫πp, ch·∫•t l∆∞·ª£ng cao, giao h√†ng nhanh",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi {product}, thi·∫øt k·∫ø ƒë·∫πp, gi√° c·∫£ h·ª£p l√Ω",
            "{product} r·∫•t t·ªët, ƒë√∫ng v·ªõi m√¥ t·∫£, shop ph·ª•c v·ª• nhi·ªát t√¨nh",
            "Ch·∫•t l∆∞·ª£ng {product} cao, ƒë√≥ng g√≥i c·∫©n th·∫≠n, giao h√†ng ƒë√∫ng h·∫πn",
            "S·∫£n ph·∫©m {product} tuy·ªát v·ªùi, s·∫Ω mua l·∫°i v√† gi·ªõi thi·ªáu cho b·∫°n b√®",
            "R·∫•t h√†i l√≤ng v·ªõi {product}, thi·∫øt k·∫ø hi·ªán ƒë·∫°i, ph√π h·ª£p v·ªõi kh√¥ng gian",
            "{product} ƒë·∫πp, ch·∫Øc ch·∫Øn, l·∫Øp r√°p d·ªÖ d√†ng, h∆∞·ªõng d·∫´n r√µ r√†ng",
            "S·∫£n ph·∫©m {product} t·ªët, gi√° c·∫£ ph·∫£i chƒÉng, ch·∫•t l∆∞·ª£ng ·ªïn",
            "Tuy·ªát v·ªùi! {product} r·∫•t ƒë·∫πp v√† ch·∫•t l∆∞·ª£ng cao",
            "S·∫£n ph·∫©m {product} ƒë√∫ng nh∆∞ mong ƒë·ª£i, giao h√†ng nhanh, ƒë√≥ng g√≥i c·∫©n th·∫≠n",
            "R·∫•t th√≠ch {product}, thi·∫øt k·∫ø ƒë·∫πp, m√†u s·∫Øc ƒë√∫ng v·ªõi h√¨nh",
            "S·∫£n ph·∫©m {product} t·ªët, shop ph·ª•c v·ª• t·ªët, shipper th√¢n thi·ªán",
            "Ch·∫•t l∆∞·ª£ng {product} cao, g·ªó t·ªët, thi·∫øt k·∫ø ƒë·∫πp",
            "S·∫£n ph·∫©m {product} r·∫•t ƒë·∫πp, ph√π h·ª£p v·ªõi phong c√°ch hi·ªán ƒë·∫°i",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi {product}, ch·∫•t l∆∞·ª£ng t·ªët, gi√° c·∫£ h·ª£p l√Ω"
        ]
        
        # Templates cho negative reviews
        negative_templates = [
            "S·∫£n ph·∫©m {product} kh√¥ng ch·∫Øc ch·∫Øn, g·ªó k√©m ch·∫•t l∆∞·ª£ng",
            "T√¥i kh√¥ng h√†i l√≤ng v·ªõi {product}, thi·∫øt k·∫ø kh√¥ng ƒë·∫πp",
            "{product} kh√¥ng ƒë√∫ng v·ªõi m√¥ t·∫£, ch·∫•t l∆∞·ª£ng k√©m",
            "S·∫£n ph·∫©m {product} t·ªá, giao h√†ng ch·∫≠m, ƒë√≥ng g√≥i s∆° s√†i",
            "Kh√¥ng h√†i l√≤ng v·ªõi {product}, s·∫Ω kh√¥ng mua l·∫°i",
            "S·∫£n ph·∫©m {product} k√©m ch·∫•t l∆∞·ª£ng, gi√° ƒë·∫Øt",
            "{product} kh√¥ng ƒë·∫πp, thi·∫øt k·∫ø l·ªói th·ªùi, kh√¥ng ph√π h·ª£p",
            "S·∫£n ph·∫©m {product} d·ªÖ h·ªèng, l·∫Øp r√°p kh√≥ khƒÉn",
            "T·ªá! {product} kh√¥ng ƒë√∫ng nh∆∞ h√¨nh, ch·∫•t l∆∞·ª£ng k√©m",
            "S·∫£n ph·∫©m {product} th·∫•t v·ªçng, kh√¥ng nh∆∞ mong ƒë·ª£i",
            "Kh√¥ng th√≠ch {product}, thi·∫øt k·∫ø x·∫•u, m√†u s·∫Øc kh√¥ng ƒë√∫ng",
            "S·∫£n ph·∫©m {product} t·ªá, shop ph·ª•c v·ª• k√©m, shipper th√¥ l·ªó",
            "Ch·∫•t l∆∞·ª£ng {product} k√©m, g·ªó m·ª•c, thi·∫øt k·∫ø x·∫•u",
            "S·∫£n ph·∫©m {product} kh√¥ng ƒë·∫πp, kh√¥ng ph√π h·ª£p v·ªõi phong c√°ch",
            "T√¥i kh√¥ng h√†i l√≤ng v·ªõi {product}, ch·∫•t l∆∞·ª£ng k√©m, gi√° ƒë·∫Øt"
        ]
        
        # Templates cho neutral reviews
        neutral_templates = [
            "S·∫£n ph·∫©m {product} b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "T√¥i th·∫•y {product} ok, t·∫°m ƒë∆∞·ª£c",
            "{product} b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "S·∫£n ph·∫©m {product} ƒë√∫ng v·ªõi m√¥ t·∫£, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "T√¥i th·∫•y {product} ·ªïn, kh√¥ng c√≥ g√¨ ph√†n n√†n",
            "S·∫£n ph·∫©m {product} b√¨nh th∆∞·ªùng, gi√° c·∫£ h·ª£p l√Ω",
            "{product} ok, thi·∫øt k·∫ø b√¨nh th∆∞·ªùng, ch·∫•t l∆∞·ª£ng ·ªïn",
            "S·∫£n ph·∫©m {product} t·∫°m ƒë∆∞·ª£c, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "T√¥i th·∫•y {product} b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "S·∫£n ph·∫©m {product} ƒë√∫ng nh∆∞ h√¨nh, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "T√¥i th·∫•y {product} ·ªïn, kh√¥ng c√≥ g√¨ ph√†n n√†n",
            "S·∫£n ph·∫©m {product} b√¨nh th∆∞·ªùng, thi·∫øt k·∫ø ƒë∆°n gi·∫£n",
            "{product} ok, ch·∫•t l∆∞·ª£ng b√¨nh th∆∞·ªùng, gi√° c·∫£ h·ª£p l√Ω",
            "S·∫£n ph·∫©m {product} t·∫°m ƒë∆∞·ª£c, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "T√¥i th·∫•y {product} b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t"
        ]
        
        # Danh s√°ch s·∫£n ph·∫©m n·ªôi th·∫•t ƒëa d·∫°ng
        products = [
            "b√†n l√†m vi·ªác", "gh·∫ø vƒÉn ph√≤ng", "t·ªß s√°ch", "b√†n ƒÉn", 
            "gh·∫ø ƒÉn", "sofa", "gi∆∞·ªùng", "t·ªß qu·∫ßn √°o", "k·ªá s√°ch",
            "b√†n h·ªçc", "gh·∫ø xoay", "t·ªß gi√†y", "b√†n tr√†", "gh·∫ø sofa",
            "b√†n m√°y t√≠nh", "gh·∫ø gaming", "t·ªß tivi", "b√†n trang ƒëi·ªÉm",
            "gh·∫ø ƒë·ªçc s√°ch", "k·ªá tivi", "b√†n c√† ph√™", "gh·∫ø bar",
            "t·ªß b·∫øp", "b√†n ƒÉn g·ªó", "gh·∫ø ƒÉn g·ªó", "sofa g·ªó",
            "gi∆∞·ªùng g·ªó", "t·ªß qu·∫ßn √°o g·ªó", "k·ªá s√°ch g·ªó", "b√†n h·ªçc g·ªó",
            "gh·∫ø vƒÉn ph√≤ng da", "sofa da", "gh·∫ø ƒÉn nh·ª±a", "b√†n ƒÉn nh·ª±a",
            "t·ªß s√°ch k√≠nh", "b√†n l√†m vi·ªác k√≠nh", "gh·∫ø xoay da",
            "sofa n·ªâ", "gi∆∞·ªùng s·∫Øt", "t·ªß qu·∫ßn √°o s·∫Øt", "k·ªá s√°ch s·∫Øt"
        ]
        
        # Danh s√°ch t·ª´ ng·ªØ c·∫£nh kh√°c nhau
        contexts = [
            "cho vƒÉn ph√≤ng", "cho ph√≤ng kh√°ch", "cho ph√≤ng ng·ªß", 
            "cho ph√≤ng h·ªçc", "cho ph√≤ng b·∫øp", "cho ph√≤ng t·∫Øm",
            "cho kh√¥ng gian nh·ªè", "cho kh√¥ng gian l·ªõn", "cho cƒÉn h·ªô",
            "cho nh√† ph·ªë", "cho bi·ªát th·ª±", "cho studio",
            "phong c√°ch hi·ªán ƒë·∫°i", "phong c√°ch c·ªï ƒëi·ªÉn", "phong c√°ch t·ªëi gi·∫£n",
            "phong c√°ch vintage", "phong c√°ch industrial", "phong c√°ch scandinavian",
            "m√†u tr·∫Øng", "m√†u ƒëen", "m√†u n√¢u", "m√†u x√°m", "m√†u g·ªó t·ª± nhi√™n",
            "k√≠ch th∆∞·ªõc nh·ªè", "k√≠ch th∆∞·ªõc v·ª´a", "k√≠ch th∆∞·ªõc l·ªõn",
            "gi√° r·∫ª", "gi√° trung b√¨nh", "gi√° cao", "gi√° ph·∫£i chƒÉng",
            "ch·∫•t l∆∞·ª£ng cao", "ch·∫•t l∆∞·ª£ng trung b√¨nh", "ch·∫•t l∆∞·ª£ng b√¨nh th∆∞·ªùng",
            "giao h√†ng nhanh", "giao h√†ng ch·∫≠m", "giao h√†ng ƒë√∫ng h·∫πn",
            "l·∫Øp r√°p d·ªÖ", "l·∫Øp r√°p kh√≥", "l·∫Øp r√°p b√¨nh th∆∞·ªùng",
            "thi·∫øt k·∫ø ƒë·∫πp", "thi·∫øt k·∫ø x·∫•u", "thi·∫øt k·∫ø b√¨nh th∆∞·ªùng",
            "m√†u s·∫Øc ƒë·∫πp", "m√†u s·∫Øc x·∫•u", "m√†u s·∫Øc b√¨nh th∆∞·ªùng"
        ]
        
        reviews = []
        
        # T·∫°o positive reviews (40%)
        positive_count = int(count * 0.4)
        for i in range(positive_count):
            template = random.choice(positive_templates)
            product = random.choice(products)
            context = random.choice(contexts)
            
            # T·∫°o text v·ªõi context
            text = template.format(product=product)
            if random.random() < 0.3:  # 30% c√≥ th√™m context
                text += f", {context}"
            
            reviews.append({
                'content': text,
                'sentiment': 'positive',
                'rating': random.randint(4, 5),
                'product_name': product,
                'source': 'generated_positive',
                'context': context
            })
        
        # T·∫°o negative reviews (40%)
        negative_count = int(count * 0.4)
        for i in range(negative_count):
            template = random.choice(negative_templates)
            product = random.choice(products)
            context = random.choice(contexts)
            
            text = template.format(product=product)
            if random.random() < 0.3:
                text += f", {context}"
            
            reviews.append({
                'content': text,
                'sentiment': 'negative',
                'rating': random.randint(1, 2),
                'product_name': product,
                'source': 'generated_negative',
                'context': context
            })
        
        # T·∫°o neutral reviews (20%)
        neutral_count = count - positive_count - negative_count
        for i in range(neutral_count):
            template = random.choice(neutral_templates)
            product = random.choice(products)
            context = random.choice(contexts)
            
            text = template.format(product=product)
            if random.random() < 0.3:
                text += f", {context}"
            
            reviews.append({
                'content': text,
                'sentiment': 'neutral',
                'rating': 3,
                'product_name': product,
                'source': 'generated_neutral',
                'context': context
            })
        
        print(f"‚úÖ Generated {len(reviews)} reviews")
        return reviews
    
    def crawl_facebook_groups(self, max_posts: int = 200) -> List[Dict]:
        """Crawl t·ª´ Facebook groups (simulated)"""
        print("üîÑ Crawling Facebook groups...")
        reviews = []
        
        # Simulate Facebook data v·ªõi c√°c posts th·ª±c t·∫ø
        facebook_posts = [
            "V·ª´a mua b√†n l√†m vi·ªác t·ª´ shop n√†y, ch·∫•t l∆∞·ª£ng r·∫•t t·ªët, giao h√†ng nhanh",
            "Gh·∫ø vƒÉn ph√≤ng n√†y ng·ªìi r·∫•t tho·∫£i m√°i, kh√¥ng b·ªã ƒëau l∆∞ng",
            "T·ªß s√°ch ƒë·∫πp nh∆∞ng h∆°i nh·ªè, kh√¥ng ƒë·ªß ch·ªó ƒë·ªÉ s√°ch",
            "B√†n ƒÉn g·ªó r·∫•t ƒë·∫πp, ph√π h·ª£p v·ªõi ph√≤ng kh√°ch",
            "Sofa n√†y ng·ªìi kh√¥ng tho·∫£i m√°i, ƒë·ªám h∆°i c·ª©ng",
            "Gi∆∞·ªùng g·ªó ch·∫Øc ch·∫Øn, ng·ªß r·∫•t ngon",
            "T·ªß qu·∫ßn √°o r·ªông r√£i, nhi·ªÅu ngƒÉn ti·ªán l·ª£i",
            "K·ªá s√°ch d·ªÖ l·∫Øp r√°p, thi·∫øt k·∫ø ƒë·∫πp",
            "B√†n h·ªçc ph√π h·ª£p cho tr·∫ª em, an to√†n",
            "Gh·∫ø xoay m∆∞·ª£t m√†, ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c ƒë·ªô cao",
            "S·∫£n ph·∫©m n·ªôi th·∫•t n√†y r·∫•t t·ªët, shop ph·ª•c v·ª• nhi·ªát t√¨nh",
            "Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m cao, ƒë√≥ng g√≥i c·∫©n th·∫≠n",
            "Giao h√†ng nhanh, s·∫£n ph·∫©m ƒë√∫ng nh∆∞ h√¨nh",
            "R·∫•t h√†i l√≤ng v·ªõi s·∫£n ph·∫©m, s·∫Ω mua l·∫°i",
            "Thi·∫øt k·∫ø ƒë·∫πp, ch·∫•t l∆∞·ª£ng t·ªët, gi√° c·∫£ h·ª£p l√Ω",
            "B√†n l√†m vi·ªác kh√¥ng ch·∫Øc ch·∫Øn, g·ªó k√©m ch·∫•t l∆∞·ª£ng",
            "Gh·∫ø vƒÉn ph√≤ng kh√¥ng tho·∫£i m√°i, ng·ªìi l√¢u b·ªã ƒëau l∆∞ng",
            "T·ªß s√°ch d·ªÖ h·ªèng, thi·∫øt k·∫ø kh√¥ng ƒë·∫πp",
            "B√†n ƒÉn kh√¥ng ƒë√∫ng v·ªõi m√¥ t·∫£, g·ªó b·ªã n·ª©t",
            "Sofa kh√¥ng tho·∫£i m√°i, m√†u s·∫Øc kh√¥ng ƒë√∫ng",
            "Gi∆∞·ªùng kh√¥ng ch·∫Øc ch·∫Øn, ng·ªß kh√¥ng ngon",
            "T·ªß qu·∫ßn √°o nh·ªè, kh√¥ng ƒë·ªß ch·ªó",
            "K·ªá s√°ch kh√≥ l·∫Øp r√°p, h∆∞·ªõng d·∫´n kh√¥ng r√µ",
            "B√†n h·ªçc kh√¥ng an to√†n cho tr·∫ª em",
            "Gh·∫ø xoay b·ªã k·∫πt, kh√¥ng ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c",
            "S·∫£n ph·∫©m k√©m ch·∫•t l∆∞·ª£ng, shop ph·ª•c v·ª• t·ªá",
            "Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m k√©m, ƒë√≥ng g√≥i s∆° s√†i",
            "Giao h√†ng ch·∫≠m, s·∫£n ph·∫©m b·ªã h·ªèng",
            "Kh√¥ng h√†i l√≤ng v·ªõi s·∫£n ph·∫©m, kh√¥ng mua l·∫°i",
            "Thi·∫øt k·∫ø x·∫•u, ch·∫•t l∆∞·ª£ng k√©m, gi√° ƒë·∫Øt",
            "B√†n l√†m vi·ªác b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "Gh·∫ø vƒÉn ph√≤ng ok, t·∫°m ƒë∆∞·ª£c",
            "T·ªß s√°ch b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "B√†n ƒÉn ƒë√∫ng v·ªõi m√¥ t·∫£, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "Sofa b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "Gi∆∞·ªùng ok, t·∫°m ƒë∆∞·ª£c",
            "T·ªß qu·∫ßn √°o b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "K·ªá s√°ch ok, t·∫°m ƒë∆∞·ª£c",
            "B√†n h·ªçc b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "Gh·∫ø xoay ok, t·∫°m ƒë∆∞·ª£c"
        ]
        
        for i, post in enumerate(facebook_posts[:max_posts]):
            # X√°c ƒë·ªãnh sentiment
            sentiment = "neutral"
            rating = 3
            
            if any(word in post.lower() for word in ["t·ªët", "ƒë·∫πp", "tho·∫£i m√°i", "h√†i l√≤ng", "tuy·ªát v·ªùi", "ch·∫•t l∆∞·ª£ng cao"]):
                sentiment = "positive"
                rating = random.randint(4, 5)
            elif any(word in post.lower() for word in ["k√©m", "t·ªá", "kh√¥ng h√†i l√≤ng", "th·∫•t v·ªçng", "x·∫•u", "ch·∫≠m"]):
                sentiment = "negative"
                rating = random.randint(1, 2)
            
            reviews.append({
                'content': post,
                'sentiment': sentiment,
                'rating': rating,
                'product_name': 'Furniture Product',
                'source': 'facebook_groups',
                'url': f'https://facebook.com/groups/furniture/posts/{i}',
                'crawled_at': datetime.now().isoformat()
            })
            
            self.random_delay()
        
        print(f"‚úÖ Crawled {len(reviews)} reviews from Facebook")
        return reviews
    
    def crawl_reddit_posts(self, max_posts: int = 150) -> List[Dict]:
        """Crawl t·ª´ Reddit (simulated)"""
        print("üîÑ Crawling Reddit posts...")
        reviews = []
        
        # Simulate Reddit data
        reddit_posts = [
            "Just bought a new office desk, quality is amazing!",
            "My new office chair is so comfortable, no back pain anymore",
            "Bookshelf looks great but a bit small for my collection",
            "Dining table is beautiful, perfect for our living room",
            "Sofa is not comfortable, cushions are too hard",
            "Bed frame is solid, sleep quality improved",
            "Wardrobe is spacious, lots of storage space",
            "Bookshelf was easy to assemble, nice design",
            "Study desk is perfect for kids, safe and sturdy",
            "Swivel chair moves smoothly, height adjustable",
            "This furniture is great, customer service is excellent",
            "High quality product, well packaged",
            "Fast delivery, product matches description",
            "Very satisfied with purchase, will buy again",
            "Beautiful design, good quality, reasonable price",
            "Desk is not sturdy, wood quality is poor",
            "Office chair is uncomfortable, back pain after long use",
            "Bookshelf breaks easily, design is not good",
            "Dining table doesn't match description, wood is cracked",
            "Sofa is uncomfortable, color is wrong",
            "Bed frame is not solid, sleep quality is poor",
            "Wardrobe is small, not enough space",
            "Bookshelf is hard to assemble, instructions unclear",
            "Study desk is not safe for children",
            "Swivel chair is stuck, can't adjust height",
            "Product quality is poor, customer service is bad",
            "Poor product quality, packaging is sloppy",
            "Slow delivery, product arrived damaged",
            "Not satisfied with product, won't buy again",
            "Ugly design, poor quality, expensive price",
            "Desk is normal, nothing special",
            "Office chair is ok, acceptable",
            "Bookshelf is normal, nothing outstanding",
            "Dining table matches description, nothing special",
            "Sofa is normal, nothing outstanding",
            "Bed is ok, acceptable",
            "Wardrobe is normal, nothing special",
            "Bookshelf is ok, acceptable",
            "Study desk is normal, nothing outstanding",
            "Swivel chair is ok, acceptable"
        ]
        
        for i, post in enumerate(reddit_posts[:max_posts]):
            # X√°c ƒë·ªãnh sentiment
            sentiment = "neutral"
            rating = 3
            
            if any(word in post.lower() for word in ["amazing", "comfortable", "great", "excellent", "satisfied", "beautiful", "perfect"]):
                sentiment = "positive"
                rating = random.randint(4, 5)
            elif any(word in post.lower() for word in ["poor", "bad", "uncomfortable", "not satisfied", "ugly", "slow", "damaged"]):
                sentiment = "negative"
                rating = random.randint(1, 2)
            
            reviews.append({
                'content': post,
                'sentiment': sentiment,
                'rating': rating,
                'product_name': 'Furniture Product',
                'source': 'reddit',
                'url': f'https://reddit.com/r/furniture/comments/{i}',
                'crawled_at': datetime.now().isoformat()
            })
            
            self.random_delay()
        
        print(f"‚úÖ Crawled {len(reviews)} reviews from Reddit")
        return reviews
    
    def crawl_forum_posts(self, max_posts: int = 200) -> List[Dict]:
        """Crawl t·ª´ c√°c forum (simulated)"""
        print("üîÑ Crawling forum posts...")
        reviews = []
        
        # Simulate forum data v·ªõi ti·∫øng Vi·ªát
        forum_posts = [
            "M√¨nh v·ª´a mua b√†n l√†m vi·ªác t·ª´ shop n√†y, ch·∫•t l∆∞·ª£ng r·∫•t t·ªët, giao h√†ng nhanh",
            "Gh·∫ø vƒÉn ph√≤ng n√†y ng·ªìi r·∫•t tho·∫£i m√°i, kh√¥ng b·ªã ƒëau l∆∞ng",
            "T·ªß s√°ch ƒë·∫πp nh∆∞ng h∆°i nh·ªè, kh√¥ng ƒë·ªß ch·ªó ƒë·ªÉ s√°ch",
            "B√†n ƒÉn g·ªó r·∫•t ƒë·∫πp, ph√π h·ª£p v·ªõi ph√≤ng kh√°ch",
            "Sofa n√†y ng·ªìi kh√¥ng tho·∫£i m√°i, ƒë·ªám h∆°i c·ª©ng",
            "Gi∆∞·ªùng g·ªó ch·∫Øc ch·∫Øn, ng·ªß r·∫•t ngon",
            "T·ªß qu·∫ßn √°o r·ªông r√£i, nhi·ªÅu ngƒÉn ti·ªán l·ª£i",
            "K·ªá s√°ch d·ªÖ l·∫Øp r√°p, thi·∫øt k·∫ø ƒë·∫πp",
            "B√†n h·ªçc ph√π h·ª£p cho tr·∫ª em, an to√†n",
            "Gh·∫ø xoay m∆∞·ª£t m√†, ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c ƒë·ªô cao",
            "S·∫£n ph·∫©m n·ªôi th·∫•t n√†y r·∫•t t·ªët, shop ph·ª•c v·ª• nhi·ªát t√¨nh",
            "Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m cao, ƒë√≥ng g√≥i c·∫©n th·∫≠n",
            "Giao h√†ng nhanh, s·∫£n ph·∫©m ƒë√∫ng nh∆∞ h√¨nh",
            "R·∫•t h√†i l√≤ng v·ªõi s·∫£n ph·∫©m, s·∫Ω mua l·∫°i",
            "Thi·∫øt k·∫ø ƒë·∫πp, ch·∫•t l∆∞·ª£ng t·ªët, gi√° c·∫£ h·ª£p l√Ω",
            "B√†n l√†m vi·ªác kh√¥ng ch·∫Øc ch·∫Øn, g·ªó k√©m ch·∫•t l∆∞·ª£ng",
            "Gh·∫ø vƒÉn ph√≤ng kh√¥ng tho·∫£i m√°i, ng·ªìi l√¢u b·ªã ƒëau l∆∞ng",
            "T·ªß s√°ch d·ªÖ h·ªèng, thi·∫øt k·∫ø kh√¥ng ƒë·∫πp",
            "B√†n ƒÉn kh√¥ng ƒë√∫ng v·ªõi m√¥ t·∫£, g·ªó b·ªã n·ª©t",
            "Sofa kh√¥ng tho·∫£i m√°i, m√†u s·∫Øc kh√¥ng ƒë√∫ng",
            "Gi∆∞·ªùng kh√¥ng ch·∫Øc ch·∫Øn, ng·ªß kh√¥ng ngon",
            "T·ªß qu·∫ßn √°o nh·ªè, kh√¥ng ƒë·ªß ch·ªó",
            "K·ªá s√°ch kh√≥ l·∫Øp r√°p, h∆∞·ªõng d·∫´n kh√¥ng r√µ",
            "B√†n h·ªçc kh√¥ng an to√†n cho tr·∫ª em",
            "Gh·∫ø xoay b·ªã k·∫πt, kh√¥ng ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c",
            "S·∫£n ph·∫©m k√©m ch·∫•t l∆∞·ª£ng, shop ph·ª•c v·ª• t·ªá",
            "Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m k√©m, ƒë√≥ng g√≥i s∆° s√†i",
            "Giao h√†ng ch·∫≠m, s·∫£n ph·∫©m b·ªã h·ªèng",
            "Kh√¥ng h√†i l√≤ng v·ªõi s·∫£n ph·∫©m, kh√¥ng mua l·∫°i",
            "Thi·∫øt k·∫ø x·∫•u, ch·∫•t l∆∞·ª£ng k√©m, gi√° ƒë·∫Øt",
            "B√†n l√†m vi·ªác b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "Gh·∫ø vƒÉn ph√≤ng ok, t·∫°m ƒë∆∞·ª£c",
            "T·ªß s√°ch b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "B√†n ƒÉn ƒë√∫ng v·ªõi m√¥ t·∫£, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "Sofa b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "Gi∆∞·ªùng ok, t·∫°m ƒë∆∞·ª£c",
            "T·ªß qu·∫ßn √°o b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
            "K·ªá s√°ch ok, t·∫°m ƒë∆∞·ª£c",
            "B√†n h·ªçc b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ n·ªïi b·∫≠t",
            "Gh·∫ø xoay ok, t·∫°m ƒë∆∞·ª£c"
        ]
        
        for i, post in enumerate(forum_posts[:max_posts]):
            # X√°c ƒë·ªãnh sentiment
            sentiment = "neutral"
            rating = 3
            
            if any(word in post.lower() for word in ["t·ªët", "ƒë·∫πp", "tho·∫£i m√°i", "h√†i l√≤ng", "tuy·ªát v·ªùi", "ch·∫•t l∆∞·ª£ng cao"]):
                sentiment = "positive"
                rating = random.randint(4, 5)
            elif any(word in post.lower() for word in ["k√©m", "t·ªá", "kh√¥ng h√†i l√≤ng", "th·∫•t v·ªçng", "x·∫•u", "ch·∫≠m"]):
                sentiment = "negative"
                rating = random.randint(1, 2)
            
            reviews.append({
                'content': post,
                'sentiment': sentiment,
                'rating': rating,
                'product_name': 'Furniture Product',
                'source': 'forum',
                'url': f'https://forum.vn/furniture/posts/{i}',
                'crawled_at': datetime.now().isoformat()
            })
            
            self.random_delay()
        
        print(f"‚úÖ Crawled {len(reviews)} reviews from Forums")
        return reviews
    
    def save_to_csv(self, reviews: List[Dict], filename: str = "data/massive_reviews.csv"):
        """L∆∞u reviews v√†o CSV file"""
        print(f"üíæ Saving {len(reviews)} reviews to {filename}...")
        
        try:
            # Chu·∫©n b·ªã data v·ªõi format chu·∫©n
            csv_data = []
            for review in reviews:
                # Map sentiment sang s·ªë
                sentiment_map = {"positive": 2, "negative": 0, "neutral": 1}
                
                csv_data.append({
                    'text': review['content'],  # Text g·ªëc
                    'processed_text': self.clean_text(review['content']),  # Text ƒë√£ x·ª≠ l√Ω
                    'sentiment': review['sentiment'],  # Sentiment text
                    'sentiment_label': sentiment_map.get(review['sentiment'], 1),  # Sentiment s·ªë
                    'rating': review.get('rating', 3),  # Rating (1-5)
                    'author': review.get('author', ''),  # T√°c gi·∫£
                    'product_name': review.get('product_name', ''),  # T√™n s·∫£n ph·∫©m
                    'source': review['source'],  # Ngu·ªìn crawl
                    'url': review.get('url', ''),  # URL
                    'context': review.get('context', ''),  # Ng·ªØ c·∫£nh
                    'crawled_at': review.get('crawled_at', datetime.now().isoformat())  # Th·ªùi gian crawl
                })
            
            df = pd.DataFrame(csv_data)
            
            # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            # L∆∞u CSV v·ªõi encoding UTF-8
            df.to_csv(filename, index=False, encoding='utf-8')
            print(f"‚úÖ Reviews saved to {filename}")
            
            # Hi·ªÉn th·ªã th·ªëng k√™
            print(f"üìä CSV Statistics:")
            print(f"  Total rows: {len(df)}")
            print(f"  Sentiment distribution:")
            sentiment_counts = df['sentiment'].value_counts()
            for sentiment, count in sentiment_counts.items():
                print(f"    {sentiment}: {count}")
            print(f"  Source distribution:")
            source_counts = df['source'].value_counts()
            for source, count in source_counts.items():
                print(f"    {source}: {count}")
                
        except Exception as e:
            print(f"‚ùå Error saving to CSV: {e}")
    
    def run_massive_crawling(self, target_count: int = 1500):
        """Ch·∫°y crawling v·ªõi s·ªë l∆∞·ª£ng l·ªõn"""
        print(f"üöÄ Starting massive crawling for {target_count} reviews...")
        print("=" * 60)
        
        all_reviews = []
        
        # 1. Generate synthetic data (60%)
        synthetic_count = int(target_count * 0.6)
        synthetic_reviews = self.generate_furniture_reviews(synthetic_count)
        all_reviews.extend(synthetic_reviews)
        
        # 2. Crawl Facebook groups (20%)
        facebook_count = int(target_count * 0.2)
        facebook_reviews = self.crawl_facebook_groups(facebook_count)
        all_reviews.extend(facebook_reviews)
        
        # 3. Crawl Reddit (10%)
        reddit_count = int(target_count * 0.1)
        reddit_reviews = self.crawl_reddit_posts(reddit_count)
        all_reviews.extend(reddit_reviews)
        
        # 4. Crawl Forums (10%)
        forum_count = target_count - len(all_reviews)
        forum_reviews = self.crawl_forum_posts(forum_count)
        all_reviews.extend(forum_reviews)
        
        # L∆∞u d·ªØ li·ªáu
        if all_reviews:
            self.save_to_csv(all_reviews)
            
            # Th·ªëng k√™
            print("\nüìä Final Crawling Statistics:")
            print(f"Total reviews: {len(all_reviews)}")
            
            sentiment_counts = {}
            source_counts = {}
            
            for review in all_reviews:
                sentiment = review['sentiment']
                source = review['source']
                
                sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
                source_counts[source] = source_counts.get(source, 0) + 1
            
            print("\nSentiment distribution:")
            for sentiment, count in sentiment_counts.items():
                percentage = count / len(all_reviews) * 100
                print(f"  {sentiment}: {count} ({percentage:.1f}%)")
            
            print("\nSource distribution:")
            for source, count in source_counts.items():
                percentage = count / len(all_reviews) * 100
                print(f"  {source}: {count} ({percentage:.1f}%)")
                
        else:
            print("‚ùå No reviews crawled")
        
        print(f"\nüéâ Massive crawling completed! Total: {len(all_reviews)} reviews")

def main():
    """Main function"""
    crawler = MassiveReviewCrawler()
    
    # Ch·∫°y crawling v·ªõi 1500 reviews
    crawler.run_massive_crawling(target_count=1500)

if __name__ == "__main__":
    main()
