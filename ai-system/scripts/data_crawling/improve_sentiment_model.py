#!/usr/bin/env python3
"""
Improve Sentiment Model - C·∫£i thi·ªán model sentiment v·ªõi d·ªØ li·ªáu m·ªõi
Quy tr√¨nh: Crawl data -> Process -> Train -> Evaluate
"""

import os
import sys
import subprocess
from pathlib import Path
import sqlite3
import pandas as pd

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

class SentimentModelImprover:
    """C·∫£i thi·ªán Sentiment Model"""
    
    def __init__(self):
        self.db_path = "data/sentiment_training.db"
        
    def run_crawling(self):
        """Ch·∫°y crawling d·ªØ li·ªáu"""
        print("üï∑Ô∏è Step 1: Crawling furniture reviews...")
        print("=" * 50)
        
        try:
            # Ch·∫°y script crawl
            result = subprocess.run([
                sys.executable, 
                "scripts/crawl_furniture_reviews.py"
            ], cwd=Path(__file__).parent.parent, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("‚úÖ Crawling completed successfully")
                print(result.stdout)
            else:
                print("‚ùå Crawling failed")
                print(result.stderr)
                return False
                
        except Exception as e:
            print(f"‚ùå Error running crawling: {e}")
            return False
            
        return True
    
    def process_data(self):
        """X·ª≠ l√Ω d·ªØ li·ªáu ƒë√£ crawl"""
        print("\nüîß Step 2: Processing crawled data...")
        print("=" * 50)
        
        try:
            # Ki·ªÉm tra file CSV c√≥ t·ªìn t·∫°i kh√¥ng
            csv_path = Path(__file__).parent.parent / "data" / "crawled_reviews.csv"
            if not csv_path.exists():
                print("‚ö†Ô∏è No crawled data found. Generating synthetic data...")
                # T·∫°o synthetic data n·∫øu kh√¥ng c√≥ crawled data
                from scripts.process_crawled_data import CrawledDataProcessor
                processor = CrawledDataProcessor()
                processor.process_all_data()
            else:
                # Ch·∫°y script process v·ªõi CSV
                result = subprocess.run([
                    sys.executable, 
                    "scripts/process_crawled_data.py"
                ], cwd=Path(__file__).parent.parent, capture_output=True, text=True)
                
                if result.returncode == 0:
                    print("‚úÖ Data processing completed successfully")
                    print(result.stdout)
                else:
                    print("‚ùå Data processing failed")
                    print(result.stderr)
                    return False
                
        except Exception as e:
            print(f"‚ùå Error processing data: {e}")
            return False
            
        return True
    
    def retrain_model(self):
        """Train l·∫°i model v·ªõi d·ªØ li·ªáu m·ªõi"""
        print("\nü§ñ Step 3: Retraining sentiment model...")
        print("=" * 50)
        
        try:
            # Ch·∫°y script train
            result = subprocess.run([
                sys.executable, 
                "scripts/train_advanced_sentiment.py",
                "/Users/macbookpro/Workspace/test_repo/shopee-reviews-sentiment-analysis/data"
            ], cwd=Path(__file__).parent.parent, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("‚úÖ Model retraining completed successfully")
                print(result.stdout)
            else:
                print("‚ùå Model retraining failed")
                print(result.stderr)
                return False
                
        except Exception as e:
            print(f"‚ùå Error retraining model: {e}")
            return False
            
        return True
    
    def evaluate_improvement(self):
        """ƒê√°nh gi√° s·ª± c·∫£i thi·ªán c·ªßa model"""
        print("\nüìä Step 4: Evaluating model improvement...")
        print("=" * 50)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # L·∫•y performance m·ªõi nh·∫•t
            cursor.execute("""
                SELECT model_name, accuracy, f1_score, precision, recall, 
                       training_samples, validation_samples, created_at
                FROM model_performance 
                ORDER BY created_at DESC 
                LIMIT 1
            """)
            
            latest_perf = cursor.fetchone()
            
            if latest_perf:
                print("üìà Latest Model Performance:")
                print(f"  Model: {latest_perf[0]}")
                print(f"  Accuracy: {latest_perf[1]:.4f}")
                print(f"  F1-score: {latest_perf[2]:.4f}")
                print(f"  Precision: {latest_perf[3]:.4f}")
                print(f"  Recall: {latest_perf[4]:.4f}")
                print(f"  Training samples: {latest_perf[5]}")
                print(f"  Validation samples: {latest_perf[6]}")
                print(f"  Created at: {latest_perf[7]}")
            
            # Th·ªëng k√™ d·ªØ li·ªáu
            cursor.execute("""
                SELECT label, COUNT(*) as count 
                FROM sentiment_training_data 
                GROUP BY label
            """)
            
            results = cursor.fetchall()
            total = sum(count for _, count in results)
            
            print(f"\nüìä Training Data Statistics:")
            print(f"  Total samples: {total}")
            
            label_names = {0: "negative", 1: "neutral", 2: "positive"}
            for label, count in results:
                percentage = count / total * 100
                print(f"  {label_names.get(label, 'unknown')}: {count} ({percentage:.1f}%)")
            
            # Th·ªëng k√™ sources
            cursor.execute("""
                SELECT source_file, COUNT(*) as count 
                FROM sentiment_training_data 
                GROUP BY source_file
                ORDER BY count DESC
            """)
            
            sources = cursor.fetchall()
            print(f"\nüìÅ Data Sources:")
            for source, count in sources:
                percentage = count / total * 100
                print(f"  {source}: {count} ({percentage:.1f}%)")
            
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Error evaluating improvement: {e}")
    
    def test_model_predictions(self):
        """Test model v·ªõi c√°c c√¢u m·∫´u"""
        print("\nüß™ Step 5: Testing model predictions...")
        print("=" * 50)
        
        try:
            # Import model
            import joblib
            model_path = "models/sentiment/advanced/vietnamese_sentiment_model.joblib"
            
            if not os.path.exists(model_path):
                print("‚ùå Model file not found")
                return False
            
            model_data = joblib.load(model_path)
            model = model_data["pipeline"]
            
            # Test samples
            test_samples = [
                "B√†n l√†m vi·ªác r·∫•t ƒë·∫πp, ch·∫•t l∆∞·ª£ng cao",
                "Gh·∫ø vƒÉn ph√≤ng kh√¥ng tho·∫£i m√°i, ng·ªìi l√¢u b·ªã ƒëau l∆∞ng",
                "T·ªß s√°ch b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát",
                "Sofa r·∫•t ƒë·∫πp v√† tho·∫£i m√°i, gi√° c·∫£ h·ª£p l√Ω",
                "Gi∆∞·ªùng kh√¥ng ch·∫Øc ch·∫Øn, g·ªó k√©m ch·∫•t l∆∞·ª£ng",
                "B√†n ƒÉn ok, t·∫°m ƒë∆∞·ª£c",
                "S·∫£n ph·∫©m n·ªôi th·∫•t r·∫•t t·ªët, giao h√†ng nhanh",
                "Kh√¥ng h√†i l√≤ng v·ªõi d·ªãch v·ª•, s·∫£n ph·∫©m b·ªã h·ªèng",
                "N·ªôi th·∫•t ƒë·∫πp, ph√π h·ª£p v·ªõi kh√¥ng gian",
                "Ch·∫•t l∆∞·ª£ng k√©m, kh√¥ng ƒë√∫ng v·ªõi m√¥ t·∫£"
            ]
            
            print("üîÆ Model Predictions:")
            for text in test_samples:
                # Preprocess
                from scripts.train_advanced_sentiment import preprocess_text
                processed_text, _ = preprocess_text(text)
                
                # Predict
                pred_proba = model.predict_proba([processed_text])[0]
                pred_label = pred_proba.argmax()
                confidence = pred_proba[pred_label]
                
                label_names = {0: "negative", 1: "neutral", 2: "positive"}
                print(f"  '{text[:50]}...' ‚Üí {label_names[pred_label]} ({confidence:.3f})")
            
            print("‚úÖ Model testing completed")
            
        except Exception as e:
            print(f"‚ùå Error testing model: {e}")
    
    def run_improvement_pipeline(self):
        """Ch·∫°y to√†n b·ªô pipeline c·∫£i thi·ªán"""
        print("üöÄ Starting Sentiment Model Improvement Pipeline")
        print("=" * 60)
        
        steps = [
            ("Crawling Data", self.run_crawling),
            ("Processing Data", self.process_data),
            ("Retraining Model", self.retrain_model),
            ("Evaluating Improvement", self.evaluate_improvement),
            ("Testing Predictions", self.test_model_predictions)
        ]
        
        for step_name, step_func in steps:
            print(f"\nüîÑ Running: {step_name}")
            success = step_func()
            
            if not success:
                print(f"‚ùå Failed at step: {step_name}")
                return False
        
        print("\nüéâ Sentiment Model Improvement Pipeline Completed Successfully!")
        return True

def main():
    """Main function"""
    improver = SentimentModelImprover()
    improver.run_improvement_pipeline()

if __name__ == "__main__":
    main()
